title;authors;year;publicationtitle;citationcount;doi;abstract;population;intervention;comparison;outcomes;context;checklater;include;testitem
3-D Display using Motion Parallax for Extended-Depth Perception;Kazutake Uehira,Masahiro Suzuki,Takuya Abekawa,;2007;2007 IEEE International Conference on Multimedia and Expo;2;https://doi.org/10.1109/ICME.2007.4285007;This paper proposes a new 3D display that can express differences between depths at extended distances of over tens of meters to meet new requirements for outdoor use. We attempted to use motion parallax for observers to perceive depth because this works as a cue at longer distances where binocular parallax, which is used in conventional 3D displays to perceive depth, does not work. We conducted subjective tests using a moving car in which observers viewed a test pattern overlapping the real view ahead of the car seen through the windshield to examine the feasibility of the 3D display we propose. The experimental results revealed that the perceived depth of a pattern could be controlled by changing its rate of expansion, demonstrating the feasibility of a 3D display for extended-depth perception using motion parallax.;0;0;0;0;0;0;0
3-dimensional personal computer system;K. Iwasaki,I. Karibe,K. Nakai,A. Ueno,;1988;IEEE Transactions on Consumer Electronics;1;https://doi.org/10.1109/30.20151;The system is composed of a personal computer, a video display, video cassette recorder (VCR), two video cameras, a 3-D scope with TN-type, high-speed, liquid-crystal shutter, and 3-D adapter used for driving the 3-D scope. To achieve stereoscopic imaging, the system uses time-sharing alternate imaging based on binocular parallax. The time-sharing period is 1/60 second, which is a single vertical period of the NTSC TV standard. The system alternately presents images for the left and right eyes on the screen at a 1/60-second period while synchronously driving the 3-D scope in which liquid-crystal shutters alternately shut up the left and right eyes of the viewer. Thus, the viewer's left eye always sees only the image for the left eye and the right eye always sees only that for the right eye.<>;0;0;0;0;0;0;0
A 2-D filtering scheme for stereo image compression using sequential orthogonal subspace updating;Sang-Hoon Seo,M.R. Azimi-Sadjadi,;2001;IEEE Transactions on Circuits and Systems for Video Technology;8;https://doi.org/10.1109/76.894282;Stereo image compression involves estimating the disparity vectors that represent the amount of binocular parallax. The mismatching problems between the left and right images greatly impact the accuracy of the reconstructed image, and hence the visual effects of the reproduced 3-D image. This paper presents a new method for compensating the mismatching effects in stereo image pairs. This 2-D filtering-based scheme uses a sequential orthogonal subspace updating (SOSU) process to project an image block onto a subset of best-basis vectors. The basis vectors are selected one by one from the neighboring blocks, as well as some typical edge blocks, forming an image-dependent set of basis vectors. This leads to the optimal representation of an image block with fewer coefficients. Simulation results on two different image pairs demonstrate the effectiveness of the SOSU scheme when compared to those of the standard least squares 2-D filtering and the hybrid disparity-compensated discrete cosine transform residual encoding schemes.;0;0;0;0;0;0;0
A 3-D (stereoscopic) X-ray imaging technique based on linear array detectors;M. Robinson,J.P.O. Evans,S.X. Godber,;1996;IEE Colloquium on Digital Mammography;0;https://doi.org/10.1049/ic:19960494;In general the problem of interpreting the three-dimensional structure of an object from an X-ray image is a difficult one. This is due to the almost complete absence of depth cues in a typical radiograph containing as it does only shape and grey scale information. The spatial information usually encountered in two-dimensional images, for example photographs, is missing. Psychological depth cues such as linear z perspective, occlusion and so on are usually present in reinforcing combinations in photographs. In order to provide X-ray images with spatial information an X-ray technique has been developed which introduces the powerful physiological depth cue of binocular parallax into the image. This system was originally designed to assist in the interpretation of X-ray images routinely encountered by operators using standard 2-D X-ray systems for the screening of passenger baggage at airports. The solution to the problem is not however specifically confined to it but is in fact more general in nature. Indeed theoretical designs have already been proposed for other X-ray screening applications including mammography.;0;0;0;0;0;0;0
A 3D display with variable depth moire pattern;Keita Nagasaki,Yue Bao,;2008;2008 SICE Annual Conference;2;https://doi.org/10.1109/SICE.2008.4654978;"In recent years, 3D display came to be used also for the vehicles. In the field of the three-dimensional display, the methods of using a parallax barrier and a lenticular lens are well-known. Like the parallax barrier and the lenticular lens, a moire type of 3D display is also proposed as one of the three-dimension systems with binocular parallax. However this method does not have a reverse stereoscopic vision area that the parallax barrier and the lenticular lens have. The display has a wide area observation zone, but it could give only a fixed depth feeling to observers. In this paper, we propose a moire type of 3D display which riot; only has a wide area observation zone, but has a variable depth by adjusting the pattern size finely with the zoom of a projector. By the estimation experiment with a prototype display, we confirmed that the proposal method can provide a variable feeling of depth continuously in a wide observation zone.";0;0;0;0;0;0;0
A 3D vision 2.1Mpixel image sensor for single-lens camera systems;Shinzo Koyama,Kazutoshi Onozawa,Keisuke Tanaka,Yoshihisa Kato,;2013;2013 IEEE International Solid-State Circuits Conference Digest of Technical Papers;2;https://doi.org/10.1109/ISSCC.2013.6487829;We present a CMOS image sensor that enables a compact 3-dimensional (3D) vision camera system comprising a single set of the sensor and a camera lens. In order to make binocular parallax, which is essential for 3D imaging, the input pupil of the camera lens is presumed to consist of the right-eye and the left-eye domains, where the pixels exclusively receiving light beams from the right-eye domain and those from the left-eye domain, are arranged alternately. In addition, the sensor features an on-chip lenticular lens to split the incident light from the two directions and a Digital Micro Lens [1,2] to focus the split light beams onto the dedicated pixels without significant crosstalk. The fabricated 3D image sensor enables not only successful stereovision imaging in color with sufficiently high sensitivity, but also accurate calculation of distance.;0;0;0;0;0;0;0
A Depth-Dependent Fusion Algorithm for Enhanced Reality Based on Binocular Vision;Chensheng Wang,Xiaoping Liu,Fei Wang,Liang Chen,;2009;2009 WASE International Conference on Information Engineering;0;https://doi.org/10.1109/ICIE.2009.95;As one of the pivot techniques in enhanced reality the fusion of virtual and real scene image often happens in two ways, either to incorporate a real object into a virtual environment, or to incorporate a virtual object into a real scene. Most of the conventional methods for the fusion are conducted at the image level, which fails to handle three-dimensional objects. In this paper, a novel depth-dependent algorithm for the fusion of virtual and real scene image in enhanced reality based on binocular vision will be proposed. The algorithm simulates the human observation process, and computes the spatial position of an image pixel by means of binocular parallax. With the assistance of object recognition techniques, the depth computation results will then be utilized to determine the spatial position of the object in the observation coordinate frame. The fusion is consequently implemented by positioning the object of interest at the right position and establishing the depth relationship with other objects in the scene. Experiment results demonstrate that the proposed algorithm is both valid and effective to achieve a high quality fusion for an enhanced reality application.;0;0;0;0;0;0;0
A Multiuser Multiperspective Stereographic QTVR Browser Complemented by Java3D Visualizer and Emulator;Michael Cohen,Noor Alamshah Bolhassan,Owen Noel Newton Fernando,;2007;Presence;3;https://doi.org/10.1162/pres.16.4.414;To support multiperspective and stereographic image display systems intended for multiuser applications, we have developed two integrated multiuser multiperspective stereographic browsers, respectively featuring IBR-generated egocentric and CG exocentric perspectives. The first one described, “VR4U2C” (‘virtual reality for you to see’), uses Apple's QuickTime VR technology and the Java programming language together with the support of the QuickTime for Java library. This unique QTVR browser allows coordinated display of multiple views of a scene or object, limited only by the size and number of monitors or projectors assembled around or among users (for panoramas or turnoramas) in various viewing locations. The browser also provides a novel solution to limitations associated with display of QTVR imagery: its multinode feature provides interactive stereographic QTVR (dubbed SQTVR) to display dynamically selected pairs of images exhibiting binocular parallax, the stereoscopic depth percept enhanced by motion parallax from displacement of the viewpoint through space coupled with rotation of the view through a 360° horizontal panorama. This navigable approach to SQTVR allows proper occlusion/disocclusion as the virtual standpoint shifts, as well as natural looming of closer objects compared to more distant ones. We have integrated this stereographic panoramic browsing application in a client/server architecture with a sibling client, named “Just Look at Yourself!” which is built with Java3D and allows realtime visualization of the dollying and viewpoint adjustment as well as juxtaposition and combination of stereographic CG and IBR displays. “Just Look at Yourself!” visualizes and emulates VR4U2C, embedding avatars associated with cylinder pairs wrapped around the stereo standpoints texture-mapped with a set of panoramic scenes into a 3D CG model of the same space as that captured by the set of panoramas. The transparency of the 3D CG polygon space and the photorealistic stereographic 360° scenes, as well as the size of the stereo goggles through which the CG space is conceptually viewed and upon which the 360° scenes are texture-mapped, can be adjusted at runtime to understand the relationship of the spaces.;0;0;0;0;0;0;0
A Novel Skip Connection Structure in Transformer;Xintao Xu,Yi Liu,Zhiyuan Zhao,Gang Chen,Zhigang Li,Huaxiang Lu,Yi Bian,;2022;2022 IEEE 2nd International Conference on Software Engineering and Artificial Intelligence (SEAI);0;https://doi.org/10.1109/SEAI55746.2022.9832084;Herein, a novel skip connection structure with double bypass is employed in Transformer. The structure introduces two linear components between the input and output. Moreover, it establishes layer normalization at the beginning of the bypass computation, enhancing the model prediction efficiency. Two methods are employed to deploy the novel skip connection structure in the Transformer. In one method, the Transformer feedforward layer used for machine translation tasks is considered as a branch of the skip connection structure. In the other method, the skip connection structure is introduced into the Transformer model used for binocular parallax calculation tasks. Experimental results show that the machine translation model with the novel skip connection structure is 2% better in BLEU index. Furthermore, in the binocular parallax calculation tasks, the EPE index of the Transformer model with the skip connection structure decreases by 3.8% compared with that of a comparison model. The Transformer with the novel skip connection structure achieves a 7.6% lower 3PX ERROR than the Transformer without the skip connection structure.;0;0;0;0;0;0;0
A Relationship Between Product Quality and Body Information of Worker and Its Application to Improvement of Productivity;Danni Wang,Yasuyo Kotake,Hiroshi Nakajima,Kentaro Mori,Yutaka Hata,;2018;2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC);0;https://doi.org/10.1109/SMC.2018.00250;In this study, we analyzed a body information feature in the soldering process in order to develop an evaluative method of the worker skills. First, we found the three types body information features. The found features were the work position, the way to hold a soldering iron, and the effect of the dominant eye and the age. Using the features of the work position and the way to hold a soldering iron, we classified the work rank into four classes. As a result of evaluating operation time and the product quality for these classes, it was confirmed that operation time and the product quality were improved as the work rank improves.;0;0;0;0;0;0;0
A Replication Study to Measure the Perceived Three-Dimensional Location of Virtual Objects in Optical See Through Augmented Reality;Farzana Alam Khan,Mohammed Safayet Arefin,Nate Phillips,J. Edward Swan,;2022;2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW);0;https://doi.org/10.1109/VRW55335.2022.00249;An important research question in optical see-through (OST) augmented reality (AR) is, how accurately and precisely can a virtual object's real world location be perceived? Previously, a method was developed to measure the perceived three-dimensional location of virtual objects in OST AR. In this research, a replication study is reported, which examined whether the perceived location of virtual objects are biased in the direction of the dominant eye. The successful replication analysis suggests that perceptual accuracy is not biased in the direction of the dominant eye. Compared to the previous study's findings, overall perceptual accuracy increased, and precision was similar.;0;0;0;0;0;0;0
A Theory of the Visual Motion Coding in the Primary Visual Cortex;Zhaoping Li,;1996;Neural Computation;1;https://doi.org/10.1162/neco.1996.8.4.705;This paper demonstrates that much of visual motion coding in the primary visual cortex can be understood from a theory of efficient motion coding in a multiscale representation. The theory predicts that cortical cells can have a spectrum of directional indices, be tuned to different directions of motion, and have spatiotemporally separable or inseparable receptive fields (RF). The predictions also include the following correlations between motion coding and spatial, chromatic, and stereo codings: the preferred speed is greater when the cell receptive field size is larger, the color channel prefers lower speed than the luminance channel, and both the optimal speeds and the preferred directions of motion can be different for inputs from different eyes to the same neuron. These predictions agree with experimental observations. In addition, this theory makes predictions that have not been experimentally investigated systematically and provides a testing ground for an efficient multiscale coding framework. These predictions are as follows: (1) if nearby cortical cells of a given preferred orientation and scale prefer opposite directions of motion and have a quadrature RF phase relationship with each other, then they will have the same directional index, (2) a single neuron can have different optimal motion speeds for opposite motion directions of monocular stimuli, and (3) a neuron's ocular dominance may change with motion direction if the neuron prefers opposite directions for inputs from different eyes.;0;0;0;0;0;0;0
A comparative evaluation of the Generative Topographic Mapping and the Elastic Net for the formation of Ocular Dominance stripes;Dror Cohen,Andrew P. Papliński,;2012;The 2012 International Joint Conference on Neural Networks (IJCNN);2;https://doi.org/10.1109/IJCNN.2012.6252815;In this paper we compare the self organising capabilities of the Generative Topographic Map (GTM) [1] and Elastic Net (EN) [2]. We analytically compare the two algorithms and examine the different ways in which they preserve topography by considering their respective ‘state space trajectories’. We present simulations that demonstrate the differences between the two algorithms. We conclude by using the GTM to simulate the formation of Ocular Dominance (OD) stripes and compare against earlier simulations using the EN. Our findings indicate that the GTM produces patterns with some of the required characteristics and match results obtained with the EN to a degree.;0;0;0;0;0;0;0
A new no-reference stereoscopic image quality assessment based on ocular dominance theory and degree of parallax;Ke Gu,Guangtao Zhai,Xiaokang Yang,Wenjun Zhang,;2012;Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012);1;;In recent years, while stereoscopic images were becoming widely applied and the corresponding technologies were substantially developed, very few stereoscopic image quality assessment metrics were proposed, especially under the condition that there is no reference image available. This paper proposes a new no-reference stereoscopic image quality assessment algorithm based on the ocular dominance theory and degree of parallax. All of our tests using the Toyama database draw two valuable conclusions. First, the performances of stereoscopic image quality assessment methods are significantly affected by difference of image qualities between the left and right images. Second, to offset the discriminations of different degrees of parallax caused by various 3D image contents is required indeed. Experiments and comparative studies are provided to confirm the effectiveness of our proposed new stereoscopic image quality metric.;0;0;0;0;0;0;0
A parametric model for synthesis of cortical column patterns;A.S. Rojer,E.L. Schwartz,;1989;International 1989 Joint Conference on Neural Networks;2;https://doi.org/10.1109/IJCNN.1989.118416;Summary form only given. The authors introduce a parametric model for columnar structure which considers the spatial form in an image-processing framework. This method permits easy synthesis of column-like structure from noise images. In particular, bandpass filtering of noise images followed by thresholding yields patterns which strongly resemble the columnar structure that has been observed in the brain. The image-oriented technique is flexible and inexpensive to compute. There are only a few independent parameters, and the role they play in column formation is apparent. The parameters for a particular column system can be readily determined from actual brain data by the use of standard image-processing techniques. The authors have used the model to process data obtained in their computer reconstruction of the pattern of ocular dominance columns in the macaque monkey. This approach avoids the necessity of constructing computationally expensive cellular models which are based on poorly understood details of neural development. The authors provide an efficient, accurate model which can be adjusted to fit a wide variety of column data.<>;0;0;0;0;0;0;0
A pointing method of an object in real space using dominant eye's view field;Y. Mitsudo,E. Miyazaki,M. Idesawa,;2004;IEEE Conference on Robotics and Automation, 2004. TExCRA Technical Exhibition Based.;0;https://doi.org/10.1109/TEXCRA.2004.1425004;In this paper, a prototype of an imaging system of dominant eye's view field was developed and a preliminary experiment was performed. When a subject is pointing to an object in the real space, the figure of the index finger is overlapped on or near from that of the pointed object in dominant eye's image. Using the prototype of imaging system, the image of the dominant eye's view field was taken and analyzed. The effectiveness of the proposed method was proven. This method can provide a simple and accurate means to specify pointed object in real space and can be applied to e.g. the welfare system for realizing higher quality of life and so on.;0;0;0;0;0;0;0
A study of stereoscopic display technology and visual fatigue caused by viewing stereoscopic images;Wu Xiao,Wang Fei,;2011;2011 IEEE 2nd International Conference on Computing, Control and Industrial Engineering;4;https://doi.org/10.1109/CCIENG.2011.6008038;The stereoscopic display technology has become a main topic in recent years and it still exists visual fatigue problem which aspects our experience greatly when view stereoscopic images. This paper analyzed the principle of stereoscopic display and then briefly introduced the stereoscopic technologies based on binocular parallax, meanwhile we also talked about the visual fatigue caused by viewing 3-D images include of the definition, phenomenon and research methods of. Finally, it prospected the developing trend of stereoscopic display technology as well as visual fatigue's impact on our health.;0;0;0;0;0;0;0
A study on the relationship between shooting conditions and cardboard effect of stereoscopic images;H. Yamanoue,M. Okui,I. Yuyama,;2000;IEEE Transactions on Circuits and Systems for Video Technology;34;https://doi.org/10.1109/76.836285;In this paper, we examine the cardboard effect by varying such image acquisition parameters as lighting intercamera distances, lens focal length, and presence or absence of motion parallax and backgrounds in program production. Subjective evaluation tests show that binocular disparity calculated from camera-separation lens selection and convergence point are dominant factors. The cardboard effect can be effectively avoided or lessened by enhancing increasing the binocular parallax. In case of actual program production, it is practical to use standard lenses or ones close in focal length to standard lenses, and to set camera separation around the same as the average eye separation of human eyes in order to mitigate the cardboard effect. When binocular disparity is small using lenses with long focal length, other cues, such as motion parallax accompanied by the relative movement between subjects and cameras, are effective.;0;0;0;0;0;0;0
A three dimensional visor display system for the postural stability analysis;M. Yoshizawa,H.S. Lin,H. Takeda,M. Ozawa,;1989;Images of the Twenty-First Century. Proceedings of the Annual International Engineering in Medicine and Biology Society,;3;https://doi.org/10.1109/IEMBS.1989.96020;A measurement system was developed to quantify the effect of altering visual feedback information on human body sway. A three-dimensional visor display was proposed to provide the eyes with stereoscopic vision depending on head motion. A pair of CCD cameras and a pair of liquid-crystal displays were used to show wide images with binocular parallax to the test subject. The head motion on the frontal plane was measured online by using the image processing unit for the video signal obtained from the CCD cameras, and an ultrasonic distance sensor was used to measure the rotation of the head on the horizontal plane. In the experiments, the subject used head rotation to track a visual reference signal. The results from the experiments reveal that the vestibular information contradictory to the visual information increased body sway.<>;0;0;0;0;0;0;0
A two layer disparity selective simple cell model;Sijing Cheng,Qiuyan Peng,Bertram E. Shi,;2016;2016 International Joint Conference on Neural Networks (IJCNN);0;https://doi.org/10.1109/IJCNN.2016.7727825;The responses of disparity selective complex cells in the mammalian visual system are often modeled by the disparity energy model. This model linearly combines inputs from binocular simple cell units, whose responses are computed by the combination of left and right eye inputs through linear binocular receptive fields, followed by half wave rectification and an expansive nonlinearity. While many complex cells have responses that can be modeled by the standard disparity energy model, there are many that cannot be. While the standard disparity energy model has been extended to account for some specific types of tuning (e.g. cells that are “monocularly responsive” in that they only respond to input from one eye, yet are disparity tuned indicating that they receive input from both eyes), actual neurons display a wider range of ocular dominance indices and disparity selectivities than can be fully accounted for by these models. Here, we describe a two layer simple cell model that can be used to construct complex cells that fully cover this range. The model combines the responses from a first layer of model monocular simple cells. By adjusting the weights from the monocular to a second binocular layer, the model can exhibit more diverse tuning properties than previously proposed models. We also show that these weights can be learned by sparse coding, and that if so, there is a strong relationship between distribution of tuning properties in the population and the input disparity statistics.;0;0;0;0;0;0;0
Accommodation response for visually equivalent light field 3D display;Munekazu Date,Hiroshi Fujii,Hideaki Kimata,Takehito Kojima,Kohei Iwata,Ryota Kimura,Akihiro Sugiura,Masaru Miyao,;2017;2017 IEEE Industry Applications Society Annual Meeting;3;https://doi.org/10.1109/IAS.2017.8101803;Visually Equivalent Light Field 3D (VELF3D) is an autostereoscopic flat-panel 3D display. Though it has a very simple structure, it can reproduce not only binocular parallax and convergence but also smooth motion parallax. It displays multiple viewing zones and uses oblong pixels and a parallax barrier to enable adjacent zones to be linearly blended well and provide continuous reproduction of motion parallax. However, the potential for accommodation reproducibility has yet to be clarified. In this paper, we demonstrate accommodation responses of monocular vision induced by changes in displayed depth as determined by an autorefractor / keratometer. We calculate point spread functions and retinal images when an observer is watching a linear blending display, and analyze mechanisms to induce accommodation.;0;0;0;0;0;0;0
Accurate vergence control in complex scenes;Taylor,Olson,Martin,;1994;1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition;11;https://doi.org/10.1109/CVPR.1994.323879;In binocular visual systems, vergence is the process of directing the gaze so that the optical axes intersect at a surface point. Correlation-based methods of disparity analysis provide fast estimates of the vergence error. Unfortunately most correlation techniques do not provide mechanisms to determine which image locations contributed to a given correlation peak. The result is that large correlation peaks may have contributions from image arena not relevant to the vergence task. This paper presents a vergence system that applies a cepstral filter to multiscale images obtained from a dominant-eye binocular sensor. As used by this system, the cepstral filter has two main advantages: it enhances targets through narrow-band signal suppression, and it supports a back-projection operation to determine the image locations associated with particular correlation peaks. The use of multiscale images allows the system to have both high resolution for precision in the final vergence and a large field of view for a wide range of initial camera orientations without undue computational cost.<>;0;0;0;0;0;0;0
Acquisition of accurate distance information in stereovision using move-parallel method for teleoperation;M. Mizukami,K. Hongte,J. Takeno,;2005;IEEE International Conference Mechatronics and Automation, 2005;3;https://doi.org/10.1109/ICMA.2005.1626723;The authors have developed a new stereo image shooting method, named the move-parallel method. There are two conventional stereo image shooting methods: the parallel-view method and the cross-eyed method. The parallel-view method allows the user to shoot and supply images that are free from geometric distortion, and thus is suitable for shooting distant views in consideration of the significant visual burden. The cross-eyed method uses the cross point to adjust the parallax of the object, but the perception of space is inevitably distorted in terms of binocular parallax. The new move-parallel method generates geometric distortion-free images by using the same shooting technique as the parallel-view method and offers easy-to-view images equivalent to those obtained with the cross-eyed method. This is achieved by moving the captured right and left images until the parallax of the object to be fixated disappears by image processing. It is important in teleoperation to capture correct information on the distance to the object to be fixated and to other objects. The authors conducted several experiments to evaluate the features of the move-parallel method. This paper reports on the method, which reduces distortion of space perception in terms of binocular parallax, provides correct distance information to the observer, and reduces the visual burden of viewing stereo images.;0;0;0;0;0;0;0
Airport Foreign Object Detection Algorithm Based on Binocular Parallax;Cai Xun,Yang Heng Zhan,;2022;2022 International Conference on Mechanical and Electronics Engineering (ICMEE);0;https://doi.org/10.1109/ICMEE56406.2022.10093485;The full name of FOD [1] is Foreign Object Debris. This paper combines binocular vision difference to realize Foreign Object Debris detection. The principle of Binocular parallax [2] simulates that the human eyes observe the same position from different observation angles, the spatial information obtained by the left and right eyes is different, and the spatial information is described by detecting this difference. In this paper, the detection of Foreign Object Detection is realized by this principle and binocular camera. Firstly, the appropriate mathematical model is established according to the three-dimensional space information of airport runway plane and binocular camera. Then, the feature points of interest in the right camera are extracted by sift detection algorithm, and then the feature points extracted by the right camera are projected into the image of the left camera according to the mathematical model established above. Finally, The Color difference similarity proposed in this paper is used to filter pixels, which can effectively and quickly detect foreign objects in the region. Experiments show that the algorithm can not only effectively detect the foreign object in the plane, but also eliminate some interference in the plane, such as cracks, and the dirt spots with large difference from the plane.;0;0;0;0;0;0;0
An Analysis of Orientation and Ocular Dominance Patterns in the Visual Cortex of Cats and Ferrets;T. M Müller,M. Stetter,M. Hübener,F. Sengpiel,T. Bonhoeffer,I. Gödecke,B. Chapman,S. Löwel,K. Obermayer,;2000;Neural Computation;0;https://doi.org/10.1162/089976600300014854;"We report an analysis of orientation and ocular dominance maps that were recorded optically from area 17 of cats and ferrets. Similar to a recent study performed in primates (Obermayer & Blasdel, 1997), we find that 80% (for cats and ferrets) of orientation singularities that are nearest neighbors have opposite sign and that the spatial distribution of singularities deviates from a random distribution of points, because the average distances between nearest neighbors are significantly larger than expected for a random distribution. Orientation maps of normally raised cats and ferrets show approximately the same typical wavelength; however, the density of singularities is higher in ferrets than in cats. Also, we find the well-known overrepresentation of cardinal versus oblique orientations in young ferrets (Chapman & Bonhoeffer, 1998; Coppola, White, Fitzpatrick, & Purves, 1998) but only a weak, not quite significant overrepresentation of cardinal orientations in cats, as has been reported previously (Bonhoeffer & Grinvald, 1993). Orientation and ocular dominance slabs in cats exhibit a tendency of being orthogonal to each other (Hüubener, Shoham, Grinvald, & Bonhoeffer, 1997), albeit less pronounced, as has been reported for primates (Obermayer & Blasdel, 1993). In chronic recordings from single animals, a decrease of the singularity density and an increase of the ocular dominance wavelength with age but no change of the orientation wavelengths were found. Orientation maps are compared with two pattern models for orientation preference maps: bandpass-filtered white noise and the field analogy model. Bandpass-filtered white noise predicts sign correlations between orientation singularities, but the correlations are significantly stronger (87% opposite sign pairs) than what we have found in the data. Also, bandpass-filtered noise predicts a deviation of the spatial distribution of singularities from a random dot pattern. The field analogy model can account for the structure of certain local patches but not for the whole orientation map. Differences between the predictions of the field analogy model and experimental data are smaller than what has been reported for primates (Obermayer & Blasdel, 1997), which can be explained by the smaller size of the imaged areas in cats and ferrets.";0;0;0;0;0;0;0
An ocellar model for optical illusion considered by the lateral geniculate body and hypercolumn;I. Okuhara,S. Osaki,;1994;Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94);0;https://doi.org/10.1109/ICNN.1994.374874;In the cerebral cortex which performs intellectual information processing of humans, the visual area which is concerned with vision as the most important information source is developed. First we give an outline about the visual information processing. The visual stimuli which are caught by the eyeball project on the retina as a 2D image. In the retina, it is translated to electric signals from the light signals by the photoreceptor, the so-called visual cells. The informations which are performed in the retina are transmitted to the lateral geniculate body (LGN), and arrive at V1. There is a regular partial structure, the so called hypercolumn (HC) in V1. It consists of the column about ocular dominance and an orientation. Neurons which respond to a contour are found in V2. This paper proposes the lower visual information processing model from the external world to V2 through the eyeball and V1. Two informations are transmitted by LGN in parallel processing from the eyeball to V1 in our model. Furthermore, we consider the representation in HC. We apply our proposed model to optical illusion in simulation.<>;0;0;0;0;0;0;0
Arbitrary Elastic Topologies and Ocular Dominance;Peter Dayan,;1993;Neural Computation;0;https://doi.org/10.1162/neco.1993.5.3.392;The elastic net, which has been used to produce accounts of the formation of topology-preserving maps and ocular dominance stripes (OD), embodies a nearest neighbor topology. A Hebbian account of OD is not so restricted—and indeed makes the prediction that the width of the stripes depends on the nature of the (more general) neighborhood relations. Elastic and Hebbian accounts have recently been unified, raising a question mark about their different determiners of stripe widths. This paper considers this issue, and demonstrates theoretically that it is possible to use more general topologies in the elastic net, including those effectively adopted in the Hebbian model.;0;0;0;0;0;0;0
Are Visual Cortex Maps Optimized for Coverage?;Miguel Á. Carreira-Perpiñán,Geoffrey J. Goodhill,;2002;Neural Computation;0;https://doi.org/10.1162/08997660260028601;The elegant regularity of maps of variables such as ocular dominance, orientation, and spatial frequency in primary visual cortex has prompted many people to suggest that their structure could be explained by an optimization principle. Up to now, the standard way to test this hypothesis has been to generate artificial maps by optimizing a hypothesized objective function and then to compare these artificial maps with real maps using a variety of quantitative criteria. If the artificial maps are similar to the real maps, this provides some evidence that the real cortex may be optimizing a similar function to the one hypothesized. Recently, a more direct method has been proposed for testing whether real maps represent local optima of an objective function (Swindale, Shoham, Grinvald, Bonhoeffer, & Hübener, 2000). In this approach, the value of the hypothesized function is calculated for a real map, and then the real map is perturbed in certain ways and the function recalculated. If each of these perturbations leads to a worsening of the function, it is tempting to conclude that the real map is quite likely to represent a local optimum of that function. In this article, we argue that such perturbation results provide only weak evidence in favor of the optimization hypothesis.;0;0;0;0;0;0;0
Asymmetric stereoscopic video encoding algorithm based on subjective visual characteristic;Shu Liu,Feng Liu,Jingjing Fan,Hongfei Xia,;2009;2009 International Conference on Wireless Communications & Signal Processing;4;https://doi.org/10.1109/WCSP.2009.5371693;In traditional asymmetric stereo video encoding scheme, one eye is represented with high quality sequence, the other eye is represented with lower quality one. However, if the low quality view is the observer's dominant eye, the masking effect will not work. Based on this human visual characteristic, this paper proposed a GOP-based resolution cross-switching asymmetric encoding scheme. By allocating degradation to both of views in a balanced way over time, our experimental results show better compression efficiency than JMVM reference software and better subjective visual quality than the traditional asymmetric stereo video encoding scheme. Our stereo video coding scheme can be a trade-off between compression performance and subjective visual quality.;0;0;0;0;0;0;0
Attentional Sampling between Eye Channels;Daniele Re,Golan Karvat,Ayelet N. Landau,;2023;Journal of Cognitive Neuroscience;0;https://doi.org/10.1162/jocn_a_02018;Our ability to detect targets in the environment fluctuates in time. When individuals focus attention on a single location, the ongoing temporal structure of performance fluctuates at 8 Hz. When task demands require the distribution of attention over two objects defined by their location, color or motion direction, ongoing performance fluctuates at 4 Hz per object. This suggests that distributing attention entails the division of the sampling process found for focused attention. It is unknown, however, at what stage of the processing hierarchy this sampling occurs, and whether attentional sampling depends on awareness. Here, we show that unaware selection between the two eyes leads to rhythmic sampling. We presented a display with a single central object to both eyes and manipulated the presentation of a reset event (i.e., cue) and a detection target to either both eyes (binocular) or separately to the different eyes (monocular). We assume that presenting a cue to one eye biases the selection process to content presented in that eye. Although participants were unaware of this manipulation, target detection fluctuated at 8 Hz under the binocular condition, and at 4 Hz when the right (and dominant) eye was cued. These results are consistent with recent findings reporting that competition between receptive fields leads to attentional sampling and demonstrate that this competition does not rely on aware processes. Furthermore, attentional sampling occurs at an early site of competition among monocular channels, before they are fused in the primary visual cortex.;0;0;0;0;0;0;0
Augmented Tangibility Surgical Navigation Using Spatial Interactive 3-D Hologram zSpace with OsiriX and Bio-Texture 3-D Organ Modeling;Maki Sugimoto,;2015;2015 International Conference on Computer Application Technologies;8;https://doi.org/10.1109/CCATS.2015.53;We developed a new spatial navigation system for medical informatics by interactive superimposing 3-D hologram and 3D printing technology. Interactive stereo display was used for the existence of an interaction between the users and stereo images of the patient's anatomy depicted on the display in the form of tracking the user's head and hand/arm position. Sensing the user's head position created motion parallax information, an immersive depth cue that can be added to the binocular parallax already present in the display. We also developed new technology of bio-texture modeling by multi-material 3D printing to form 3D organ textures and structures. Based on patient-specific MDCT data sets, regions of interest were segmented using DICOM viewer OsiriX application. After generating 3D surface models of the organ and STL file out of the patient's 3D data, the inkjet 3D printer created a 3D multi-material organ replica. Sensing the user's hand or arm position using motion sensor attached the patient's life size 3-D printed organ model, allowed the user to manipulate the spatial attributes of the virtual and real printed organs, which can enhance spatial reasoning and augmented tangibility. These tangible organ replication provide better anatomical reference tool as a tailormade simulation and navigation, and contribute to medical safety and accuracy, less-invasiveness and improvement of the medical education for students and trainees.;0;0;0;0;0;0;0
Automatic stereoscopic presentation of functions of two variables;Bela Julesz,Joan E. Miller,;1962;The Bell System Technical Journal;1;https://doi.org/10.1002/j.1538-7305.1962.tb02424.x;Spatial models of functions of two variables are often a valuable research tool. Nomograms and artistic relief drawings in two dimensions are difficult to prepare and still lack the direct impact of a spatial object. It has been demonstrated (see Ref. 2) that objects with a randomly dotted surface permit the determination of binocular parallax and, thus, can be seen in depth even though they are devoid of all other depth cues. This random surface presentation has the advantage that the random brightness points can be evenly and densely placed, whereas the classical contour-line projection at equally spaced heights may leave empty spaces between adjacent contour-lines. A digital computer is used to generate the three-dimensional image of a given z = f (x, y) function and to wrap its surface with points of random brightness. The stereo projections of the function are obtained and, when viewed stereoscopically, give the impression of the three-dimensional object as being viewed along the z-axis. The random surface prevents the accumulation of clusters of uniform regions or periodic patterns which yield ambiguities when fused. Two stereo demonstrations are given of surfaces obtained by this method.;0;0;0;0;0;0;0
Automultiscopic 3D Displays System Model and Evaluation;Jiayu Bi,Dan Zeng,Zhijiang Zhang,Zhihua Dong,;2009;2009 WRI World Congress on Computer Science and Information Engineering;4;https://doi.org/10.1109/CSIE.2009.350;An automultiscopic display system model with a real parallel camera layout is derived. And a solution to evaluate the performance of 3D system models is also discussed. According to the theory of computer vision and binocular parallax, the mathematical expressions map the real object space to the perceived image space by 4*4 homogenous matrices. The model is estimated quantitatively by considering perceived depth range, 3D depth adjusting sensitivity and the fusion limitation of human eyes. The performance of the model is also compared with other two models. The analysis shows this model has higher 3D depth adjusting sensitivity and larger fusion limitation. The parameters of shooting and display can be adjusted more precisely so that the perceived depth can be controlled more effectively. The theory and simulation results prove this model has better value of reference in real shooting condition.;0;0;0;0;0;0;0
Beyond flat panning and zooming: dolly-enhanced SQTVR;N.A. Bolhassan,W.L. Martens,M. Cohen,;2002;First International Symposium on Cyber Worlds, 2002. Proceedings.;0;https://doi.org/10.1109/CW.2002.1180925;"This paper describes a novel solution to limitations associated with interactive display of immersive stereographic imagery via Apple's QuickTime Virtual Reality (QTVR) technology. A unique multinode implementation providing Stereographic QTVR (termed here SQTVR) enables display of pairs of images exhibiting binocular parallax, and the stereoscopic depth percept that results is enhanced by motion parallax inherent in a subtle translation of the viewpoint through the displayed 3D scene. Stereoscopic depth is maintained as a user pans freely through a complete 360/spl deg/ horizontal panorama, while the system imposes a slight dollying in and out of the scene as a user's view rotates left or right. In addition, SQTVR solves two problems that can be observed when users of conventional QTVR technology change viewing positions, and these are problems that generally interfere with a user's sense of immersion and telepresence. First, objects that should be revealed (""disoccluded"") by a change in viewing position remain occluded behind objects in the foreground of the image. Second, objects that should loom large as they approach the viewing position are displayed in an unchanging proportion relative to image elements in the background. SQTVR's multinode implementation addresses these two limitations of conventional QTVR technology in a natural way by tiling a plane with equilateral triangles connecting potential viewing positions.";0;0;0;0;0;0;0
Binocular Mutual Learning for Improving Few-shot Classification;Ziqi Zhou,Xi Qiu,Jiangtao Xie,Jianan Wu,Chi Zhang,;2021;2021 IEEE/CVF International Conference on Computer Vision (ICCV);25;https://doi.org/10.1109/ICCV48922.2021.00829;Most of the few-shot learning methods learn to transfer knowledge from datasets with abundant labeled data (i.e., the base set). From the perspective of class space on base set, existing methods either focus on utilizing all classes under a global view by normal pretraining, or pay more attention to adopt an episodic manner to train meta-tasks within few classes in a local view. However, the interaction of the two views is rarely explored. As the two views capture complementary information, we naturally think of the compatibility of them for achieving further performance gains. Inspired by the mutual learning paradigm and binocular parallax, we propose a unified framework, namely Binocular Mutual Learning (BML), which achieves the compatibility of the global view and the local view through both intraview and cross-view modeling. Concretely, the global view learns in the whole class space to capture rich inter-class relationships. Meanwhile, the local view learns in the local class space within each episode, focusing on matching positive pairs correctly. In addition, cross-view mutual interaction further promotes the collaborative learning and the implicit exploration of useful knowledge from each other. During meta-test, binocular embeddings are aggregated together to support decision-making, which greatly improve the accuracy of classification. Extensive experiments conducted on multiple benchmarks including cross-domain validation confirm the effectiveness of our method1.;0;0;0;0;0;0;0
Binocular depth perception of computer-generated patterns;Bela Julesz,;1960;The Bell System Technical Journal;54;https://doi.org/10.1002/j.1538-7305.1960.tb03954.x;The perception of depth involves monocular and binocular depth cues. The latter seem simpler and more suitable for investigation. Particularly important is the problem of finding binocular parallax, which involves matching patterns of the left and right visual fields. Stereo pictures of familiar objects or line drawings preclude the separation of interacting cues, and thus this pattern-matching process is difficult to investigate. More insight into the process can be gained by using unfamiliar picture material devoid of all cues except binocular parallax. To this end, artificial stereo picture pairs were generated on a digital computer. When viewed monocularly, they appear completely random, but if viewed binocularly, certain correlated point domains are seen in depth. By introducing distortions in this material and testing for perception of depth, it is possible to show that pattern-matching of corresponding points of the left and right visual fields can be achieved by first combining the two fields and then searching for patterns in the fused field. By this technique, some interesting properties of this fused binocular field are revealed, and a simple analog model is derived. The interaction between the monocular and binocular fields is also describea. A number of stereo images that demonstrate these and other findings are presented.;0;0;0;0;0;0;0
Binocular image dominant mechanism;Jing-Jing Ge,Zhao-Rong Lin,Da-Kai Zhu,;2012;2012 IEEE International Geoscience and Remote Sensing Symposium;0;https://doi.org/10.1109/IGARSS.2012.6350406;To improve the resolution and identification of remote sensing, a system has been established to obtain human binocular image dominant mechanism. The influence of binocular vision on the neural contrast sensitivity function (NCSF) of vision system is studied with a calculation method. The contrast sensitivity function (CSF) of visual system and modulation transfer function (MTF) of the eye's optical system are firstly measured with correspondent instruments respectively. Then the NCSF is calculated as the ratio of CSF and MTF. Two individual human are involved in this study. It is shown that the resolution and identification of binocular summation is large better than that of monocular results. The dominant eye that takes precedence has no relationship with the quality of the eye's optical system.;0;0;0;0;0;0;0
Binocular interface: Interaction techniques considering binocular parallax for a large display;Keigo Yoshimura,Takefumi Ogawa,;2015;2015 IEEE Virtual Reality (VR);2;https://doi.org/10.1109/VR.2015.7223422;There have been many studies on intuitive user interfaces for large displays by using pointing movements. However, if a user cannot reach a display, object manipulations on the display are difficult because the user will see duplicate fingers due to binocular parallax. We propose Binocular Interface, which enables interactions with an object by using two pseudo fingers. In a prototype, pointing positions on the display are estimated on the basis of the positions of eyes and a finger detected by an RGB-D camera. We implemented three basic operations (select, move, and resize) using duplicate fingers and evaluated each operation.;0;0;0;0;0;0;0
Breaking Rotational Symmetry in a Self-Organizing Map Model for Orientation Map Development;M. Riesenhuber,H.-U. Bauer,D. Brockmann,T. Geisel,;1998;Neural Computation;0;https://doi.org/10.1162/089976698300017719;"We analyze the pattern formation behavior of a high-dimensional self-organizing map (SOM) model for the competitive projection of ON-center-type and OFF-center-type inputs to a common map layer. We mathematically show, and numerically confirm, that even isotropic stimuli can drive the development of oriented receptive fields and an orientation map in this model. This result provides an important missing link in the spectrum of pattern formation behaviors observed in SOM models. Extending the model by including further layers for binocular inputs, we also investigate the combined development of orientation and ocular dominance maps. A parameter region for combined patterns exists; corresponding maps show a preference for perpendicular intersection angles between iso-orientation lines and ocularity domain boundaries, consistent with experimental observations.";0;0;0;0;0;0;0
Can Hebbian Volume Learning Explain Discontinuities in Cortical Maps?;Graeme J. Mitchison,Nicholas V. Swindale,;1999;Neural Computation;1;https://doi.org/10.1162/089976699300016115;It has recently been shown that orientation and retinotopic position, both of which are mapped in primary visual cortex, can show correlated jumps (Das & Gilbert, 1997). This is not consistent with maps generated by Kohonen's algorithm (Kohonen, 1982), where changes in mapped variables tend to be anticorrelated. We show that it is possible to obtain correlated jumps by introducing a Hebbian component (Hebb, 1949) into Kohonen's algorithm. This corresponds to a volume learning mechanism where synaptic facilitation depends not only on the spread of a signal from a maximally active neuron but also requires postsynaptic activity at a synapse. The maps generated by this algorithm show discontinuities across which both orientation and retinotopic position change rapidly, but these regions, which include the orientation singularities, are also aligned with the edges of ocular dominance columns, and this is not a realistic feature of cortical maps. We conclude that cortical maps are better modeled by standard, non-Hebbian volume learning, perhaps coupled with some other mechanism (e.g., that of Ernst, Pawelzik, Tsodyks, & Sejnowski, 1999) to produce receptive field shifts.;0;0;0;0;0;0;0
Cepstral filtering on a columnar image architecture: a fast algorithm for binocular stereo segmentation;Y. Yeshurun,E.L. Schwartz,;1989;IEEE Transactions on Pattern Analysis and Machine Intelligence;75;https://doi.org/10.1109/34.192471;Many primate visual cortex architectures have a prominent feature responsible for the mixing of left and right eye visual data: ocular dominance columns represent thin (about 5-10 minutes of arc) strips of alternating left and right eye input to the brain. It is shown that such an architecture, when operated upon with a cepstral filter, provides a strong cue for binocular stereopsis. Specifically, the vector of binocular disparity may be easily identified in the output of the (columnar based) cepstral filter. This algorithm is illustrated with application to a random dot stereogram and to natural images. The authors suggest that this provides a fast algorithm for stereo segmentation, in a machine vision context. In a biological context, it may provide a computational rationale for the existence of columnar systems with regard to both ocular mixing and other visual modalities that have a columnar architecture.<>;0;0;0;0;0;0;0
Competition for Neurotrophic Factors: Mathematical Analysis;T. Elliott,N. R. Shadbolt,;1998;Neural Computation;0;https://doi.org/10.1162/089976698300016927;Neurotrophic factors, particularly the neurotrophin gene family of neurotrophic factors, are implicated in activity-dependent anatomical plasticity in the visual cortex and at the neuromuscular junction. Accumulating evidence implicates neurotrophic factors as possible mediators of activity-dependent competition between afferents, leading to the segregation of afferents' arbors on the target space. We present a biologically plausible mathematical model of competition for neurotrophic factors. We show that the model leads to anatomical segregation, provided that the levels of neurotrophic factors released in an activity-independent manner, or the levels available by exogenous infusion, are below a critical value, which we derive. Above this critical value, afferent segregation breaks down. We also show that the model segregates afferents even in the presence of very highly correlated patterns of afferent activity. The model is therefore ideally suited for application to the development of ocular dominance columns in the kitten visual cortex.;0;0;0;0;0;0;0
Construction of Autostereograms Taking into Account Object Colors and Its Applications for Steganography;Yusuke Tsuda,Yonghao Yue,Tomoyuki Nishita,;2008;2008 International Conference on Cyberworlds;1;https://doi.org/10.1109/CW.2008.86;Information on appearances of three-dimensional objects are transmitted via the Internet, and displaying objects plays an important role in a lot of areas such as movies and video games. An autostereogram is one of the ways to represent three-dimensional objects taking advantage of binocular parallax, by which depths of objects are perceived. In previous methods, the colors of objects were ignored when constructing autostereogram images. In this paper, we propose a method to construct autostereogram images taking into account color variation of objects, such as shading. We also propose a technique to embed color information in autostereogram images. Using our technique, autostereogram images shown on a display change, and viewers can enjoy perceiving three-dimensional object and its colors in two stages. Color information is embedded in a monochrome autostereogram image, and colors appear when the correct color table is used. Our technique can also be used for steganography to hide color information. Moreover, file size gets smaller than that of an original autostereogram image because indexed colors are used. Therefore, the 3D images constructed using our method are useful for transmission through the cyberworld.;0;0;0;0;0;0;0
Conversion Method From Moving Pictures Captured by High-Definition Television Camera on Kaguya (SELENE) Into Stereoscopic Images;Masato Miura,Jun Arai,Junichi Yamazaki,Hisayuki Sasaki,Makoto Okui,Shin-Ichi Sobue,Fumio Okano,;2010;Journal of Display Technology;0;https://doi.org/10.1109/JDT.2010.2052452;We present a method of converting moving pictures captured by a single high-definition television camera mounted on the Japanese lunar orbiter Kaguya (Selenological and Engineering Explorer, SELENE) into stereoscopic images. As objects in the moving pictures look as if they are moving vertically, vertical disparity is caused by the time offset of the sequence. The vertical disparity is converted into horizontal disparity by rotating the images by 90 degs. We developed models of the capture and display systems, and geometrically and numerically derived convergence points of observers' eyes. We confirmed that observers could perceive a stereoscopic effect with binocular parallax for the lunar surface at distances of several hundreds of kilometers.;0;0;0;0;0;0;0
Design of virtual reality robot based on android platform;Jiawang Bai,Xin Wang,Wenbin Zhang,Chaojian Zhuang,Mengdi Pan,;2017;2017 Fourth International Conference on Image Information Processing (ICIIP);1;https://doi.org/10.1109/ICIIP.2017.8313798;Combining the virtual reality (VR) technology with hardware, this paper proposes a remote control system for robot based on Android and Arduino platform. A binocular camera and Pan/Tilt/Zoom (PTZ) are used to build dynamic view, VR headset display device with an Android phone is used to receive video and binocular parallax is used to form stereoscopic images. The control scheme adopts the command word recognition technology based on the Auto Speech Recognition of iFLYTEK. Then it sends out the corresponding control signal by judging the input voice. The experiment results show this system feasible and reliable.;0;0;0;0;0;0;0
Development of EOG-Based Communication System Controlled by Eight-Directional Eye Movements;Kenji Yamagishi,Junichi Hori,Michio Miyakawa,;2006;2006 International Conference of the IEEE Engineering in Medicine and Biology Society;44;https://doi.org/10.1109/IEMBS.2006.259914;A communication support interface controlled by eye movements and voluntary eye blink has been developed for disabled individuals with motor paralysis who cannot speak. Horizontal and vertical electro-oculograms were measured using two electrodes attached above and beside the dominant eye and referring to an earlobe electrode and amplified with AC-coupling in order to reduce the unnecessary drift. Eight directional cursor movements and one selected operation were realized by logically combining the two detected channel signals based on threshold setting specific to the individuals. As experimental results using a projected screen keyboard, processing speed was improved to 12.1 letters/min. while the accuracy was 90.4%.;0;0;0;0;0;0;0
Development of Oriented Ocular Dominance Bands as a Consequence of Areal Geometry;H.-U. Bauer,;1995;Neural Computation;0;https://doi.org/10.1162/neco.1995.7.1.36;"It has been hypothesized that the different appearance of ocular dominance bands in the cat and the monkey is a consequence of the different mapping geometries in these species (LeVay et al. 1985; Anderson et al. 1988). Here I investigate the impact of areal geometries on the preferred direction of ocular dominance bands in two adaptive map formation models, the self-organizing feature map and the elastic net algorithm. In the case of the self-organizing feature map, the occurrence of instabilities that correspond to ocular dominance bands can be analytically investigated. The instabilities automatically yield stripes of correct orientation. These analytic results are complemented by simulations. In the case of the elastic net algorithm, simulations reveal two different parameter regimes of the algorithm, only one of which leads to stripes of correct orientation. The results suggest that neighborhood preservation in visual maps is enforced in the backward direction, such that neighboring cells in the cortex have neighboring receptive fields, and not vice versa.";0;0;0;0;0;0;0
Development of a tool that increases / reverses the user's binocular parallax with optical elements to change the feeling of depth of a physical object;Tomotaka Horiuchi,Yutaro Yamada,Shigeru Wesugi,;2017;2017 IEEE International Conference on Mechatronics and Automation (ICMA);0;https://doi.org/10.1109/ICMA.2017.8015843;In daily situation such as driving a car or playing a ball sport, the feeling of depth is important to understand the distance between an object and a performer. There decline in a feeling of depth due to aging influences on performance. Furthermore, because many people may be unaware of a decline in their feeling of depth, it is typically thought that it's difficult to monitor the degree of change in a person's feeling of depth correctly and to prepare the person for the decline. Authors thus intend to propose a unique experience of simulating a change in the feeling of depth relating to aging. The present paper explains a method and a tool for changing the feeling of depth of a physical object in real environment. We focused on the influence on a feeling of depth by changing only binocular parallax, and constructed a tool that increases / reverses the user's binocular parallax. In consideration of tiredness resulting from a long time use, we designed the tool to conform optical information received when using the tool to that received when observing physical objects directly. Through the movement of objective mirrors and ocular prisms, the tool changes the user's binocular parallax arbitrarily. It was reported from experiences that the feeling of depth changed by using this tool.;0;0;0;0;0;0;0
Disparity Analysis of Images;Stephen T. Barnard,William B. Thompson,;1980;IEEE Transactions on Pattern Analysis and Machine Intelligence;556;https://doi.org/10.1109/TPAMI.1980.4767032;An algorithm for matching images of real world scenes is presented. The matching is a specification of the geometrical disparity between the images and may be used to partially reconstruct the three-dimensional structure of the scene. Sets of candidate matching points are selected independently in each image. These points are the locations of small, distinct features which are likely to be detectable in both images. An initial network of possible matches between the two sets of candidates is constructed. Each possible match specifies a possible disparity of a candidate point in a selected reference image. An initial estimate of the probability of each possible disparity is made, based on the similarity of subimages surrounding the points. These estimates are iteratively improved by a relaxation labeling technique making use of the local continuity property of disparity that is a consequence of the continuity of real world surfaces. The algorithm is effective for binocular parallax, motion parallax, and object motion. It quickly converges to good estimates of disparity, which reflect the spatial organization of the scene.;0;0;0;0;0;0;0
Dynamic Visual Acuity (DVA) Binocular Summation and DVA Performance Factors;Masaki Emoto,;2010;Journal of Display Technology;2;https://doi.org/10.1109/JDT.2010.2045635;Recent developments in video technology enable us to view wider field-of-view (FOV) images using wide flat-panel displays, as one would a television monitor. New video systems with high resolution beyond HDTV have been proposed, but it is not clear that their motion picture quality will be sufficient if traditional video system frame rates are used. In the assessment of picture quality, it is recommended to screen viewers' static visual acuity (SVA), but not their dynamic visual acuity (DVA). Furthermore, the methodology to measure the DVA appropriate for the participants in such an assessment of picture quality has not yet been clearly established. In this paper, we have studied, experimentally, the changes in DVA performance by looking at differences in DVA measurement conditions as the first step to establish the methodology. We successfully verified the improvement of DVA performance in binocular viewing compared to monocular viewing. We also looked at the differences in DVA performance as a function of viewing conditions, including eye rotation direction (nasal or temporal direction), shape of the visual target (a Landolt C or E chart), ocular dominance (dominant or non-dominant eye), and the anisotropy or the difference in target orientation of a laterally moving target.;0;0;0;0;0;0;0
Effect of Binocular Cortical Misalignment on Ocular Dominance and Orientation Selectivity;Harel Shouval,Nathan Intrator,C. Charles Law,Leon N Cooper,;1996;Neural Computation;4;https://doi.org/10.1162/neco.1996.8.5.1021;We model a two-eye visual environment composed of natural images and study its effect on single cell synaptic modification. In particular, we study the effect of binocular cortical misalignment on receptive field formation after eye opening. We show that binocular misalignment affects principal component analysis (PCA) and Bienenstock, Cooper, and Munro (BCM) learning in different ways. For the BCM learning rule this misalignment is sufficient to produce varying degrees of ocular dominance, whereas for PCA learning binocular neurons emerge in every case.;0;0;0;0;0;0;0
Effect of Display Technology on the Crosstalk Perception in Stereoscopic Video Content;Lili Wang,Yan Tu,Li Chen,Panpan Zhang,Tingting Zhang,Kees Teunissen,Ingrid Heynderickx,;2012;IEEE Transactions on Circuits and Systems for Video Technology;4;https://doi.org/10.1109/TCSVT.2012.2198135;3-D, and in particular stereoscopic, displays are believed to have great prospects. Due to imperfections in the optical and electronic components, however, some image distortions still exist in these displays. Among them, crosstalk is considered to be a very annoying one. The aim of the current research is to investigate crosstalk perception and its influence on image quality when rendering dynamic image sequences on two types of stereoscopic displays: a hold-type liquid-crystal display with patterned retarder and circular polarizing glasses, and an impulse-type digital light processing display with shutter glasses. Results show that the dynamic behavior of the displays has an impact on crosstalk perception. Perceived motion blur can mask crosstalk visibility, especially at low binocular parallax, which limits the crosstalk-induced image quality degradation.;0;0;0;0;0;0;0
Effect of Ocular Dominance on Touch Position;Seung-Ryeol Kim,Jong-Man Kim,Joohwan Kim,Seung-Woo Lee,;2016;Journal of Display Technology;0;https://doi.org/10.1109/JDT.2016.2553219;"In this paper, we analyzed the effect of ocular dominance on touch positions when users touched a three-dimensional (3D) object on a two-dimensional (2D) touch panel while watching a 3D display. We performed a psychophysical experiment where eight subjects (four right-eye-dominant and four left-eyedominant) participated. When touching 3D objects with uncrossed disparities, touch positions were mainly influenced by ocular dominance and depth of the 3D image (P <; 10-189). For crossed disparities, touch positions were mainly influenced by ocular dominance (P <; 10-18). However, the depth of the 3D image had no significant effect on touch positions (P = 0.783). Our findings can help to design more accurate and comfortable interfaces for 3D systems with touch feedback.";0;0;0;0;0;0;0
Effect of eye dominance on the perception of stereoscopic 3D video;Amin Banitalebi-Dehkordi,Mahsa T. Pourazad,Panos Nasiopoulos,;2014;2014 IEEE International Conference on Image Processing (ICIP);4;https://doi.org/10.1109/ICIP.2014.7025704;Asymmetric schemes have widespread applications in the 3D video transmission pipeline. The significance of eye dominance becomes a concern when designing such schemes. In this paper, in order to investigate the effect of eye dominance on the perceptual 3D video quality, a database of representative asymmetric stereoscopic sequences is prepared and the overall 3D quality of these sequences is evaluated through subjective experiments. Experiment results showed that viewers find an asymmetric video more pleasant when the view with higher quality is projected to their dominant eye. Moreover, the eye dominance changes the mean opinion quality score by 16 % at most, a result caused by slight asymmetric video compression. For all other representative types of asymmetry, the statistical difference is much lower and in some cases even negligible.;0;0;0;0;0;0;0
Effects of dominance and laterality on iris recognition;Amanda Sgroi,Kevin W. Bowyer,Patrick Flynn,;2012;2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops;2;https://doi.org/10.1109/CVPRW.2012.6239215;Eye dominance, the tendency to prefer to process visual input from one eye over the other, is a little discussed topic in iris biometrics. It has been seen in experiments that one eye tends to have improved performance over the other. One possible cause of this variation in performance could be the distribution of eye dominance among the subject population. In this paper we explore the effects of eye dominance on iris recognition. We also show how eye dominance can be used to guide the development of a single-eye recognition system. An exploration of the correlation between eyedness and handedness is also presented.;0;0;0;0;0;0;0
Efficient stereo rendering of large 3D datasets based on binocular suppression;Il-Kyu Shin,Hyeon-Joong Kim,Soo-Mi Choi,Seon-Min Rhee,;2015;2015 International Conference on Big Data and Smart Computing (BIGCOMP);1;https://doi.org/10.1109/35021BIGCOMP.2015.7072855;As the demand for stereo 3D content increases in the various fields, many types of devices for displaying stereo contents have been developed such as TVs, laptops, and mobile devices. Thus, efficient rendering methods that can process massive stereo data on those devices are becoming more important as well as reducing a feeling of visual discomfort of the viewer. In this paper, we analyze binocular suppression in an aspect of human visual perception, and present a point-based stereo rendering method to process high-resolution 3D data based on binocular suppression. To reduce visual discomfort which occurs in the process of the stereo rendering, we develop a simplification method by extending spectral sampling. Using the adaptive sampling, we can improve the rendering quality, especially in the visually sensitive areas as well as reducing the size of datasets.;0;0;0;0;0;0;0
Elastic Net Model of Ocular Dominance: Overall Stripe Pattern and Monocular Deprivation;Geoffrey J. Goodhill,David J. Willshaw,;1994;Neural Computation;1;https://doi.org/10.1162/neco.1994.6.4.615;The elastic net (Durbin and Willshaw 1987) can account for the development of both topography and ocular dominance in the mapping from the lateral geniculate nucleus to primary visual cortex (Goodhill and Willshaw 1990). Here it is further shown for this model that (1) the overall pattern of stripes produced is strongly influenced by the shape of the cortex: in particular, stripes with a global order similar to that seen biologically can be produced under appropriate conditions, and (2) the observed changes in stripe width associated with monocular deprivation are reproduced in the model.;0;0;0;0;0;0;0
Error Analysis on Camera Calibration in Binocular Stereo Vision;Aixia Guo,Juntao Xiong,;2009;2009 International Conference on Information Engineering and Computer Science;2;https://doi.org/10.1109/ICIECS.2009.5364788;In order to resolve the problem of orientation on longan (or lychee)-harvesting robot, an experimentation on camera calibration based on binocular parallax theory was given. Logical foci and baseline between cameras were obtained by taking photos on character dots located on the calibration board, dealing with and analyzing the experimental data. After that, source of errors existing in experiment system were analyzed, and corresponding methods of compensation were also discussed in the paper. Analysis results show that the method of total visual errors correction based on polar geometry transform more coincide with our experiment system.;0;0;0;0;0;0;0
Evaluation of 3DTV Service using Asymmetric View Coding Based on MPEG-2;Hari Kalva,Lakis Christodoulou,Borko Furht,;2007;2007 3DTV Conference;4;https://doi.org/10.1109/3DTV.2007.4379454;This paper presents the results of the 3DTV quality evaluation on autostereoscopic displays using asymmetric view coding. Asymmetric view coding encodes the stereo views with different quality. It has been shown that the human visual system is able to compensate for this asymmetric view quality and present a good quality 3D video. Asymmetric video coding can be exploited to reduce the bandwidth requirements for 3DTV services. The key factors that affect the asymmetric video coding are the compression algorithms, the human visual system, and the 3D display. We conducted a subjective evaluation of 3D video with asymmetric view quality and encoded using MPEG-2. We also studied the impact of eye dominance on the perceived quality. We show that asymmetric view coding can be used to reduce the bandwidth requirements of 3DTV services based on MPEG-2 view coding.;0;0;0;0;0;0;0
Exploiting Binocular Rivalry: Presenting Different Contents on Dominant and Non-dominant Eyes;Jinhyun Park,Jun Park,;2015;2015 IEEE International Symposium on Mixed and Augmented Reality Workshops;0;https://doi.org/10.1109/ISMARW.2015.14;One of the ergonomic issues of wearing see-though displays is binocular rivalry, which is one of visual perception phenomena. Binocular rivalry happens when different images are rendered to each eye. In this paper, we introduce the potential of making use of binocular rivalry rather than mitigating it when a stereo see-through HMD is worn. We designed experiments where major contents were presented on the dominant eyes and minor contents (e.g., menus) were displayed on the non-dominant eyes. According to preliminary tests, presenting different contents on dominant and non-dominant eyes is feasible if both contents do not overlap, or only one of them is bright. Switching brightness was also helpful in attaining user's attention. By presenting different contents on dominant and non-dominant eyes, users could also observe the real environments more conveniently than presenting a single content on both eyes.;0;0;0;0;0;0;0
Extraction and Investigation of Dominant Eye-Gaze Pattern in Train Driver’s Visual Behavior Using Markov Cluster Algorithm;Yukio Horiguchi,Takaya Suzuki,Tetsuo Sawaragi,Hiroaki Nakanishi,Tomoharu Takimoto,;2016;2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS);1;https://doi.org/10.1109/SCIS-ISIS.2016.0126;In the present study, dominant eye-gaze patterns in professional train drivers' visual behavior are investigated using the Markov Cluster (MCL) algorithm. Applying the MCL algorithm results in a common gaze pattern showing a sort of perception tactic the drivers usually follow. The drivers repetitively move their gaze ahead soon after looking at somewhere else, independently of their years of experience. They are, however, found different in that experienced drivers can consistently follow the tactic while inexperienced drivers cannot. Time variation in the number of attentive pattern deviations demonstrates that, as well as the inexperienced drivers made higher frequency and larger fluctuations of pattern deviation, there were several particular segments in the route in which intensive pattern deviations arose in common. Inexperienced drivers would make intensive pattern deviations in such route segments that may have higher requirements of their cognitive resources.;0;0;0;0;0;0;0
Eye-dominance-guided Foveated Rendering;Xiaoxu Meng,Ruofei Du,Amitabh Varshney,;2020;IEEE Transactions on Visualization and Computer Graphics;28;https://doi.org/10.1109/TVCG.2020.2973442;Optimizing rendering performance is critical for a wide variety of virtual reality (VR) applications. Foveated rendering is emerging as an indispensable technique for reconciling interactive frame rates with ever-higher head-mounted display resolutions. Here, we present a simple yet effective technique for further reducing the cost of foveated rendering by leveraging ocular dominance - the tendency of the human visual system to prefer scene perception from one eye over the other. Our new approach, eye-dominance-guided foveated rendering (EFR), renders the scene at a lower foveation level (with higher detail) for the dominant eye than the non-dominant eye. Compared with traditional foveated rendering, EFR can be expected to provide superior rendering performance while preserving the same level of perceived visual quality.;0;0;0;0;0;0;0
Fiberscope-type environmental monitoring devices with binocular parallax accommodation mechanism for stereoscopic observation;K. Hosotani,S. Maeda,O. Tohyama,H. Ito,;1997;Proceedings IEEE The Tenth Annual International Workshop on Micro Electro Mechanical Systems. An Investigation of Micro Structures, Sensors, Actuators, Machines and Robots;1;https://doi.org/10.1109/MEMSYS.1997.581869;A fiberscope-type environmental monitoring device is suitable for observation in narrow spaces that cannot be observed by conventional technology. The goal of developing this device is advanced functions such as stereoscopic and microscopic observation. The binocular parallax can be varied by bending the fiberscope. The position of the stereoscopic observation area is shifted by changing the binocular parallax. Therefore, the operator can observe the object without having to move the fiberscope back and forth and can also get optimum images on a 3D display by accommodation of the binocular parallax. Microactuators are necessary to accommodate the binocular parallax. This stereoscope consists of two fiberscopes, an SMA (shape memory alloy) coil spring, a bias spring plate, and two support plates, and is covered with a stainless steel pipe 5 mm in outer diameter. The fiberscope consists of an image fiber with 12,000 pixels and six light guide fibers. The outer diameter of the fiberscope is 1.3 mm. The wire diameter and the outer diameter of the SMA coil spring are 75 /spl mu/m and 300 /spl mu/m, respectively. The SMA coil spring is stretched and fixed to the tip of the fiberscopes. We devised a system for stereoscopic observation and an environmental monitoring device using two fiberscope. We also defined the stereoscopic parameters necessary for stereoscopic observation.;0;0;0;0;0;0;0
Force display system for realization of cut-in-feeling of virtual sheet object by scissors;H. Wakamatsu,S. Aoyagi,K. Takahara,M. Yasuna,;1995;Proceedings of 1995 IEEE International Conference on Robotics and Automation;2;https://doi.org/10.1109/ROBOT.1995.525405;A stereoscopic cutting of virtual object in a real space using a human binocular parallax is discussed. A scissors-type edged-tool with 2-degree of freedom is developed for the realization of reactive force feeling on the cutting into stereoscopically viewed virtual object. An image of sheet is given as a virtual object for cutting. The reactive force is provided for the tool, by which fingers obtain feeling of cutting according to given physical properties to the image. The stereoscopic cutting makes clear a trace of the cutting point of scissors characterized by a different color in a virtual object given as an image. This paper describes first the construction of a scissors-type edged-tool for cutting. Then, force display system is synthesized providing feeling of cutting of materials by the edged-tool according to their given properties.;0;0;0;0;0;0;0
Formation and automatic calculation of the dynamic time parallax in binocular vision system;Mergen Y. Shyyrap,Yuriy M. Shyyrap,;2013;2013 14th International Conference of Young Specialists on Micro/Nanotechnologies and Electron Devices;0;https://doi.org/10.1109/EDM.2013.6641981;The article discusses the possible application of machine vision dynamic time parallax to determine the spatial parameters of objects stereo video surveillance. First described in detail the principle of formation and excretion of cyclic time parallax monocular and binocular systems. Were shown the formula for calculating the spatial parameters on the basis of temporary cyclical parallax. The use of Dynamic Time binocular parallax in vision systems allows automatic namedetail images of stereo pairs and automatically determines spatial parameters observed as static-ray and dynamic objects stereo video surveillance.;0;0;0;0;0;0;0
Fundamental research on three-dimensional pointing movement in consideration of change of X-and Z-axis rotation angles;Atsuo Murata,Takehito Hayami,Takanori Akiyama,;2013;The SICE Annual Conference 2013;0;;With the widespread of touch - panel interface, there are many pointing tasks that requires us to touch a target with a finger-tip. In such a situation, the touch-panel display is not necessarily installed parallel to the frontal or coronal plane. Possibly, it is installed at various locations with different installation angles in a three-dimensional space. Fitts' law models a one-dimensional movement. The pointing movement is, in nature, three-dimensional. However, few studies have made an attempt to model pointing movements in a three-dimensional space. In order to obtain insight into three-dimensional modeling of pointing movement, it was explored how X- and Z- axis rotation angles affected the pointing time. The effects of eye dominance on pointing movement were also examined. As a result, it tended that the pointing time got shorter under some conditions of X- and Z-axis rotation especially when the movement of arm was conducted within area of the preferred hand.;0;0;0;0;0;0;0
Gaze Estimation Based on Difference Residual Network;Bei Yan,Xiangyu Tang,;2021;2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI);1;https://doi.org/10.1109/CISAI54367.2021.00131;Because of the variabilities in eye shapes and inner eye structures among individuals, the universal models that regress gaze directions directly from a single face or eye image through the neural network obtain limited accuracies. There is a person-specific gaze bias caused by the kappa angle between the model’s predicted and the actual gaze direction. Currently, people-specific models are usually established through calibration to increase accuracy. This paper proposes a novel estimation method of gaze direction based on the Differential Residual Network (D-ResNet),Which works by training the D-ResNet to predict gaze difference between two eye images (the same eye of the same subject) to eliminate gaze bias. At test time, only a few person - specific calibration samples are needed to infer the new eye image’s gaze direction. Our model also incorporates the head pose vector to improve the robustness to free-head. Moreover, our left and right eye models are trained and tested separately which can select the dominant eye model based on the test error to predict gaze. Experiments on 2 public datasets validate our approach outperforms state-of-the-art person-independent and person- specific gaze estimation models. In particular, our model doesn’t fail to calibrate even if there is only one calibration sample.;0;0;0;0;0;0;0
Geometrical analysis of puppet-theater and cardboard effects in stereoscopic HDTV images;H. Yamanoue,M. Okui,F. Okano,;2006;IEEE Transactions on Circuits and Systems for Video Technology;69;https://doi.org/10.1109/TCSVT.2006.875213;A fundamental element of stereoscopic image production is to geometrically analyze the conversion from real space to stereoscopic images by binocular parallax under various shooting and viewing conditions. This paper reports on this analysis, particularly on the setting of the optical axes of three-dimensional (3-D) cameras, which has received little attention in the past. First, we identified the conditions for setting the optical axes that maintain linearity during the conversion from real space to stereoscopic images. We then clarified, in geometrical terms, the shooting and viewing conditions and also conditions under which the puppet-theater effect and cardboard effect occur. The results showed that the parallel camera configuration, by which optical axes are kept parallel to each other, does not produce the puppet-theater effect as the apparent magnification (lateral magnification) of a shooting target is not dependent on the shooting distance. However, the toed-in camera configuration, where the apparent magnification of a shooting target is dependent on the shooting distance, may produce this effect. The cardboard effect is shown to be likely to occur for both camera configurations by defining this phenomenon by the ratio of depthwise reproduction magnification (depth magnification) and apparent reproduction magnification (lateral magnification). Lastly, the paper reports on the relationship between the results of this analysis and those of subjective evaluation experiments. The results need a closer examination by using many more images.;0;0;0;0;0;0;0
HVS-Based Quality Assessment Metrics for 3-D Images;Sumei Li,Wei Xiang,Fuwei Cheng,Ruichao Zhao,Chunping Hou,;2010;2010 Second WRI Global Congress on Intelligent Systems;3;https://doi.org/10.1109/GCIS.2010.273;Significant efforts from both the academia and industry have been devoted to advance three-dimensional (3-D) imaging technologies. However, accurate and easy-to-use visual quality assessment metrics still lack for 3-D images. In this paper, we propose three objective quality assessment metrics for 3-D images taking into consideration a set of relevant visual characteristic factors, including contrast sensitivity, multi-channel and binocular parallax characteristics. The human visual signal-to-noise ratio (HVSNR), parallax distortion ratio (PDR), and different peak signal-to-noise ratio (DPSNR) are the three independent objective quality assessment metrics proposed in this paper. Experimental results show that the quality assessment results based upon the proposed metrics are consistent with the quality grades obtained by subjective assessment.;0;0;0;0;0;0;0
Hebbian Learning of Recurrent Connections: A Geometrical Perspective;Mathieu N. Galtier,Olivier D. Faugeras,Paul C. Bressloff,;2012;Neural Computation;1;https://doi.org/10.1162/NECO_a_00322;We show how a Hopfield network with modifiable recurrent connections undergoing slow Hebbian learning can extract the underlying geometry of an input space. First, we use a slow and fast analysis to derive an averaged system whose dynamics derives from an energy function and therefore always converges to equilibrium points. The equilibria reflect the correlation structure of the inputs, a global object extracted through local recurrent interactions only. Second, we use numerical methods to illustrate how learning extracts the hidden geometrical structure of the inputs. Indeed, multidimensional scaling methods make it possible to project the final connectivity matrix onto a Euclidean distance matrix in a high-dimensional space, with the neurons labeled by spatial position within this space. The resulting network structure turns out to be roughly convolutional. The residual of the projection defines the nonconvolutional part of the connectivity, which is minimized in the process. Finally, we show how restricting the dimension of the space where the neurons live gives rise to patterns similar to cortical maps. We motivate this using an energy efficiency argument based on wire length minimization. Finally, we show how this approach leads to the emergence of ocular dominance or orientation columns in primary visual cortex via the self-organization of recurrent rather than feedforward connections. In addition, we establish that the nonconvolutional (or long-range) connectivity is patchy and is co-aligned in the case of orientation learning.;0;0;0;0;0;0;0
High-speed and Low-Latency Ocular Parallax Rendering Improves Binocular Fusion in Stereoscopic Vision;Yuri Mikawa,Masahiro Fujiwara,Yasutoshi Makino,Hiroyuki Shinoda,;2023;2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW);0;https://doi.org/10.1109/VRW58643.2023.00210;Most of the current virtual/augmented reality (VR/AR) displays use binocular parallax to present 3D images. However, they do not consider ocular parallax, which refers to the slight movement of the viewpoint with eye rotation, such as saccade. A commercial head-mounted display (HMD) has a large latency in realizing ocular parallax rendering. In our study, a high-speed (1,000 fps) and low-latency (average 4.072 ms) ocular-parallax-rendering device was assembled, and its effect was examined wherein a reasonable approximation algorithm for viewpoint was applied. A user study experiment employing a random dot stereogram (RDS) showed improvements in binocular fusion, the causes of which are comprehensively discussed.;0;0;0;0;0;0;0
Holographic 3-D display viewable from all horizontal directions by using a single high-speed SLM;Yusuke Sando,Daisuke Barada,Toyohiko Yatagai,;2015;2015 14th Workshop on Information Optics (WIO);0;https://doi.org/10.1109/WIO.2015.7206895;Holographic display is considered to be one of the most ideal three-dimensional display modalities. However, there are still some crucial problems to be resolved. The narrow viewing zone angle and the smallness of reconstructed images are one of them. There is a trade-off relation between the viewing zone angle and the size of the reconstructed image. The only way to improve both two properties is to increase the pixel number of a spatial light modulator (SLM). A technical method to equivalently increase such a pixel number based on the time division method was proposed by Takaki and Okada. In this method, by using a high-speed SLM such as a digital micromirror device (DMD), horizontal viewing zone angle was considerably enlarged. However, full motion parallax could not be realized although binocular parallax was achieved. To address this problem, this paper presents a method which enables such a full motion parallax, namely, look-around property from all horizontal directions.;0;0;0;0;0;0;0
Human Attention and fatigue for AR Head-Up Displays;Haruhiko Okumura,Kazumitsu Shinohara,;2016;2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct);4;https://doi.org/10.1109/ISMAR-Adjunct.2016.0102;We proposed and developed a novel monocular windshield augmented reality projector: WARP for AR and head-up display (HUD) applications. They use monocular vision that eliminates the depth cues caused by binocular parallax information. Our developed WARP system achieved not only a high hyper-reality performance with free depth perception and high visibility but also low eye-fatigue and wide field of attention.;0;0;0;0;0;0;0
Interactive medical visualization with floating images;Sandor Markon,Satoshi Maekawa,Ahmet Onat,Hiroshi Furukawa,;2012;2012 ICME International Conference on Complex Medical Engineering (CME);4;https://doi.org/10.1109/ICCME.2012.6275719;"The new optical device `DCRA' is capable of projecting floating images, that is, undistorted real images of displays. Such floating images are different from stereoscopic (so-called `3D') images as they provide most of the depth clues like motional parallax and accommodation, in addition to binocular parallax; thus they are suitable for long-term, close range observation, which is required in medical work. We have developed a prototype system using floating images to visualize volumetric medical data, such as CT or MRI scans. In this system, the visible section can be freely selected by the user, and it is displayed in the air at the correct location, to help the user in creating internally a volumetric model. The image can be superimposed on wireframes or other reference objects, and the user can place volumetric markers inside the displayed sections. We plan to cooperate with medical professionals to evaluate our system as an aid in complex medical imaging work.";0;0;0;0;0;0;0
Journey of Cepstral filter from a mathematical function to biological phenomenon used to reconstruct stereoscopic disparity;Sheena Sharma,C. M. Markan,;2012;2012 2nd National Conference on Computational Intelligence and Signal Processing (CISP);0;https://doi.org/10.1109/NCCISP.2012.6189696;This paper gives a new outlook to the Cepstral algorithm. The name seems to be an outdated one, but this is the only unique and interesting algorithm, which is applied on pattern similar to Ocular Dominance Pattern (ODC) in Primate Visual Cortex. Unless the signals from left and right eyes are placed simultaneously, the disparity cannot be detected. Therefore, it has a great significance in the sphere of stereo vision. The paper puts the life back to the existing algorithm. By definition, Cepstral algorithm is power spectrum of log of power spectrum. In the paper, it is shown how the power spectrum can be estimated using Gabor filters. The Gabor filter in itself has the biological resemblance. It is a function used to depict receptive field or simple cell. Other relation used in this paper, is between power spectrum and Gabor energy, whose model is similar to complex cells in Cortex. With Gabor filters analysis on pattern similar to ODC gives the model comparable to biology. The use of Gabor filters in the Cepstral algorithm instead of Fast Fourier Transform (FFT) also eliminates the line which makes the algorithm different from the methods using Gabor filters.;0;0;0;0;0;0;0
Low Luminance Measurement Based on Binocular Ranging;Chen Zhao,Zhangrong Zhao,Wenzhuo Chen,;2018;2018 5th International Conference on Systems and Informatics (ICSAI);0;https://doi.org/10.1109/ICSAI.2018.8599401;In order to realize long-distance and high-precision binocular measurement in low luminance environment, this paper gives a new method which is based on binocular parallax principle and triangulation reconstruction theory, by constructing a portable low luminance prototype system using a stable and efficacious feature extraction method adaptive for low luminance image. Moreover it implements an accurate and optimizational method for the whole system. In the end, the experiment data show that the method is highly robust and precise, and the relative error of the corrected results could be reduced to around 0.1% with twice error compensation.;0;0;0;0;0;0;0
Measurement of 3D Visual Fatigue Using Event-Related Potential (ERP): 3D Oddball Paradigm;Hyung-Chul O. Li,Junho Seo,Keetaek Kham,Seunghyun Lee,;2008;2008 3DTV Conference: The True Vision - Capture, Transmission and Display of 3D Video;59;https://doi.org/10.1109/3DTV.2008.4547846;"Rare tools to measure 3D visual fatigue that is critical in the study of 3D human factor have been examined for their reliability and validity. The purpose of the present research was to develop a paradigm to measure 3D visual fatigue using background EEG and ERP signals. We have developed ""3D oddball paradigm"" that revealed the effect of binocular parallax and presentation duration on 3D visual fatigue. Subjective 3D visual fatigue was also measured. Power of beta frequencies increased as watching duration increased and it was much stronger in 3D rather than in 2D condition. More importantly, P700 delayed as watching duration increased as well as in 3D rather than in 2D condition. Similar pattern of results was obtained in the measured subjective 3D visual fatigue. These results suggest that the 3D oddball paradigm would measure 3D visual fatigue correctly and reliably.";0;0;0;0;0;0;0
Measuring visual axis as an independent variable from a fixation distance;T. Hayami,K. Shidoji,S. Horimoto,H. Matsugashita,;2002;IEEE International Conference on Systems, Man and Cybernetics;0;https://doi.org/10.1109/ICSMC.2002.1175559;Our pilot study suggested that while fixating on a stationary object binocularly, each line of sight of the two eyes does not always go directly toward the object. Therefore, we experimentally investigated the amount of the displacement of the pupil center while the fixation point was changed transversally. The subjects were instructed to fixate on three targets arranged horizontally with intervals of nine degrees. The distance from the subject to the targets was any of 0.5 m, 1.0 m and 1.5 m. A significant difference of the amount of the displacement of the pupil center was observed relative to the fixation distance. The positions of the node of the line of sight, which provide no relationship between the fixation distance and the pupil center displacement, were calculated. The node of the line of sight of the non-dominant eye was nearer to the fixation panels than that of the dominant eye. Considering this, such a node would be effective for the precise measurement of gazing point.;0;0;0;0;0;0;0
Model of Static Accommodative Behavior in Human Amblyopia;George K. Hung,Kenneth J. Ciuffreda,John L. Semmlow,Steven C. Hokoda,;1983;IEEE Transactions on Biomedical Engineering;23;https://doi.org/10.1109/TBME.1983.325069;When a target is moved from far to near, the normal accommodative system responds by changing the crystalline lens power until the blur of the retinal image is reduced to an acceptable level for clear vision. This feedback mechanism, along with the experimentally derived deadspace operator (representing the depth of field), forward-loop gain, and tonic accommodative bias level have been successfully incorporated into a static model of the normal accommodative system. We extended this model to the investigation of static accommodative responses in amblyopic eyes. The experimentally derived accommodative controller gain of the amblyopic eye was typically smaller than in the fellow dominant eye. In addition, the experimentally derived depth of field was increased in most amblyopic eyes, while the accommodative bias showed no consistent difference between the two eyes. The decrease in accommodative controller gain and increase in depth of field were sufficient to account for the reduction of accommodative responses found in amblyopic eyes. Theoretically, the model provides a conceptual framework for understanding the static accommodative deficits found in amblyopic eyes. Practically, the accommodative controller gain parameter provides a means for uniform assessment of normal and abnormal accommodative function, both experimentally and in the clinic environment.;0;0;0;0;0;0;0
Models of Orientation and Ocular Dominance Columns in the Visual Cortex: A Critical Comparison;E. Erwin,K. Obermayer,K. Schulten,;1995;Neural Computation;14;https://doi.org/10.1162/neco.1995.7.3.425;Orientation and ocular dominance maps in the primary visual cortex of mammals are among the most thoroughly investigated of the patterns in the cerebral cortex. A considerable amount of work has been dedicated to unraveling both their detailed structure and the neural mechanisms that underlie their formation and development. Many schemes have been proposed, some of which are in competition. Some models focus on development of receptive fields while others focus on the structure of cortical maps, i.e., the arrangement of receptive field properties across the cortex. Each model used different means to determine its success at reproducing experimental map patterns, often relying principally on visual comparison. Experimental data are becoming available that allow a more careful evaluation of models. In this contribution more than 10 of the most prominent models of cortical map formation and structure are critically evaluated and compared with the most recent experimental findings from macaque striate cortex. Comparisons are based on properties of the predicted or measured cortical map patterns. We introduce several new measures for comparing experimental and model map data that reveal important differences between models. We expect that the use of these measures will improve current models by helping determine parameters to match model maps to experimental data now becoming available from a variety of species. Our study reveals that (1) despite apparent differences, many models are based on similar principles and consequently make similar predictions, (2) several models produce orientation map patterns that are not consistent with the experimental data from macaques, regardless of the plausibility of the models' suggested physiological implementations, and (3) no models have yet fully accounted for both the local and the global relationships between orientation and ocular dominance map patterns.;0;0;0;0;0;0;0
Monocular hyperrealistic virtual and augmented reality display;Haruhiko Okumura,Takashi Sasaki,Aira Hotta,Kazumitsu Shinohara,;2014;2014 IEEE Fourth International Conference on Consumer Electronics Berlin (ICCE-Berlin);6;https://doi.org/10.1109/ICCE-Berlin.2014.7034326;We proposed and developed a novel monocular hyper- realistic Head-Dome Projector: MHDP for an amusement application and a novel monocular windshield augmented reality projector: WARP for AR and head-up display (HUD) applications. They use monocular vision that eliminates the depth cues caused by binocular parallax information. Our developed MHDP and WARP system achieved a high hyper-reality performance with free depth perception and high visibility.;0;0;0;0;0;0;0
Multi-view stereoscopic angle model and it's application;Hao Cheng,Ping An,Hejian Li,Zhijiang Zhang,Zhaoyang Zhang,;2012;2012 International Conference on Audio, Language and Image Processing;2;https://doi.org/10.1109/ICALIP.2012.6376773;This paper establishes a multi-view stereoscopic angle model. Through the principle of optical imaging and binocular parallax, factors which impact on stereo angle can be found out. Using multi-view stereoscopic angle model, we can quantitatively simulate multi-view stereoscopic display system and find the relationship between shooting distance and stereo angle. Depending on the formula for the maximum fusion limit of the human eyes, theoretical minimum shooting distance can be calculated. Multi-view stereo angle model can be a better guide to multi-view stereoscopic display system.;0;0;0;0;0;0;0
NeuroGene: integrated simulation of gene regulation, neural activity and neurodevelopment;R. Storjohann,G.F. Marcus,;2005;Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.;2;https://doi.org/10.1109/IJCNN.2005.1555869;A challenge to understanding the mind and brain is to integrate biochemical, genetic, developmental and neuroscientific information. We present a system for integrated simulation of biochemistry, neurodevelopment and neural activity within a unifying framework of genetic control. Using this system, we have developed a novel model for the formation of topographic projections. We also simulate activity-dependent developmental processes which underlie receptive field refinement and ocular dominance column formation. As an illustration of the overall utility of integrated neurogenetic simulation, we show how axon guidance and learning together may explain the results of a critical study of topographic map development (Brown et al., 2000, Cell).;0;0;0;0;0;0;0
Neuromorphic building blocks for adaptable cortical feature maps;C. M. Markan,Priti Gupta,;2007;2007 IFIP International Conference on Very Large Scale Integration;2;https://doi.org/10.1109/VLSISOC.2007.4402464;‘Time-staggered Winner-Take-All’ is a novel CMOS analog circuit that computes ‘sum of weighted inputs” implemented as floating gate pFET ‘synapse’[ 11]. Feedback circuit of the cell exploits adaptation dynamics of floating gate FETs refining its weights in response to stimulation by patterned inputs distributed over time. This paper discusses the application of ‘ts-WTA’ cell as a core learning circuit in designing adaptive neuromorphic feature selective cells for a variety of visual cortical features such as ocular dominance, orientation selectivity etc. An array of these is-WTA cells when embedded on an RC network exhibits reaction-diffusion type clustering based on feature selective response. The cell’s adaptive behavior resembles Stent’s physiological variant of competitive Hebb learning [21] and hence has potential to act as a building block in design of adaptable feature maps in different cortices.;0;0;0;0;0;0;0
No-Reference Stereoscopic Image Quality Assessment Considering Binocular Disparity and Fusion Compensation;Feng Jinhui,Sumei Li,Yongli Chang,;2021;2021 International Conference on Visual Communications and Image Processing (VCIP);0;https://doi.org/10.1109/VCIP53242.2021.9675398;In this paper, we propose an optimized dual stream convolutional neural network (CNN) considering binocular disparity and fusion compensation for no-reference stereoscopic image quality assessment (SIQA). Different from previous methods, we extract both disparity and fusion features from multiple levels to simulate hierarchical processing of the stereoscopic images in human brain. Given that the ocular dominance plays an important role in quality evaluation, the fusion weights assignment module (FWAM) is proposed to assign weight to guide the fusion of the left and the right features respectively. Experimental results on four public stereoscopic image databases show that the proposed method is superior to the state-of-the-art SIQA methods on both symmetrical and asymmetrical distortion stereoscopic images.;0;0;0;0;0;0;0
Noise reduction scheme of temporal and spatial filter for 3D video real-time processing;Hun Ho Ham,Jong Hak Kim,Chan-oh Park,Yong Han-Kim,Jun dong Cho,;2011;2011 International SoC Design Conference;1;https://doi.org/10.1109/ISOCC.2011.6138621;In this paper, we suggest a motion adaptive noise elimination method in moving pictures, which combines temporal filtering and spatial filtering for real time processing of 3D images. To realize 3D pictures, two sets of images taken by a two-lens camera are rectified. And then, a disparity map is generated using binocular parallax of the rectified two sets of images. At this point, temporal filtering and spatial filtering are applied to generate a disparity map with less noise that also enables real time processing of obtaining high quality 3D images. Temporal filtering corrects errors occurred in the disparity map. Spatial filtering clarifies the boundaries of objects from the background, calibrates images again to reduce noises or surrounding error, and reinforces the edges lost in the images, to get a disparity map of high performance. Our approach showed 6.4dB increment in image quality, realizing the algorithm using RTL(Resister Transfer Level) in real time processing.;0;0;0;0;0;0;0
Object recognition and simultaneous indoor location algorithm with stereo camera;Xingli Gan,Baoguo Yu,Shuang Li,Qiangwei Jiang,Lu Huang,;2018;2018 Ubiquitous Positioning, Indoor Navigation and Location-Based Services (UPINLBS);0;https://doi.org/10.1109/UPINLBS.2018.8559917;Visual SLAM mainly depends on the measurement data of camera for dead reckoning, it is difficult to maintain the positioning accuracy and stability for a long time. Therefore, visual SLAM can’t be widely used in indoor positioning at present. The algorithm of object recognition and simultaneous indoor location is proposed in this paper, which combines the technology of object recognition based on deep learning, image feature matching and binocular parallax positioning. Using a low cost binocular stereo camera to output the object category and its three-dimensional position in camera coordinate system. Finally, the static and dynamic indoor positioning tests are carried out, the indoor horizontal positioning error for static test is 74 mm, the indoor horizontal positioning error for dynamic test is less than 250 mm. When the distance between object and camera becomes larger, the positioning error becomes larger. When the parallax becomes larger, the positioning error becomes smaller.;0;0;0;0;0;0;0
Online Panorama Image Generation for a Disaster Rescue Vehicle;Kanat Sovetov,Jun-Sik Kim,Doik Kim,;2019;2019 16th International Conference on Ubiquitous Robots (UR);1;https://doi.org/10.1109/URAI.2019.8768497;We introduce our online panorama generation system for armored rescue vehicles in an extreme disaster. To make the whole system fireproof and heatproof, all the cameras are embedded around the vehicle body, and this makes the panorama stitching suffer from binocular parallax. Because vehicle and remote operators should observe its current surroundings, the panorama image should be generated online in an acceptable time.We explain how to calculate the initial alignment of input camera image on the cylindrical canvas in advance, and how to merge the overlapped image by removing the binocular parallax. Structures for the data transfer is also discussed. Experiments show that the current implementation can generate and share the panoramic image with remote operators successfully.;0;0;0;0;0;0;0
Ontogenetic development of retinotopy and of ocular dominance columns;G. Barna,P. Erdi,;1991;IJCNN-91-Seattle International Joint Conference on Neural Networks;0;https://doi.org/10.1109/IJCNN.1991.155412;"A mathematical model of the activity-dependent self-organizing mechanism is given for the unified description of the ontogenetic formation of ocularity domains and of the retinotopy. The model is also capable of describing the plasticity of ocular dominance columns. According to the model the connections between cells are not preprogrammed genetically; only a certain algorithm is given to select favorable connections. In accordance with K.D. Miller et al. (1989), the role of activities is emphasized. The model of Miller et al. is based on four biological features which are also explicitly incorporated into the authors' models, with a different technical realization. While Miller et al. set up a differential equation, the authors' model is described as a multistage algorithm. Another main difference is that the authors use a two-level neurodynamic model taking explicitly into consideration even the single neuron activity dynamics.<>";0;0;0;0;0;0;0
"Optical Imaging of Electrically Evoked Visual Signals in Cats: II. ICA ""Harmonic Filtering"" Noise Reduction";Spencer C. Chen,Yan T. Wong,Luke E. Hallum,Norbert B. Dommel,Shaun L. Cloherty,John W. Morley,Gregg J. Suaning,Nigel H. Lovell,;2007;2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society;2;https://doi.org/10.1109/IEMBS.2007.4353056;"Optical imaging of intrinsic signals (OIS) is a tool for visualizing differential areas in the primary visual cortex devoted to visual functions such as ocular dominance and spatial orientation preferences. The OIS methodology was employed to verify visual cortical response to a retinal vision prosthesis whereby electrical stimulation is applied to the neural retina in order to elicit visual percepts. However, OIS recording is quite susceptible to cardiac and respiratory artifact, and inherent noise related to the measurement process. This complicates the identification of evoked signals using standard ensemble averaging based image processing. We therefore developed an independent component analysis (ICA) ""harmonic filtering"" technique to improve the signal-to-noise ratio. This technique is capable of reducing noise components, highlighting response signals to visual and electrical stimuli. Particularly, we demonstrated extraction of an ocular dominance map due to corneal stimulation and localized cortical activation due to intravitreal stimulation.";0;0;0;0;0;0;0
Ordinal and metric structure of smooth surfaces from parallax;G. Baratoff,;1996;Proceedings of 13th International Conference on Pattern Recognition;3;https://doi.org/10.1109/ICPR.1996.546033;The work presented in this paper is a first attempt at evaluating an ordinal representation for the local shape of smooth surface patches. To this end we investigate the reliability of estimating the tilt and slant components of the local surface orientation from binocular parallax. This is of interest because parallax is a commonly used cue, but has not been evaluated as to its susceptibility to image measurement errors. Our theoretical sensitivity analysis shows that the tilt is less sensitive than the slant to errors in the estimation of the viewing geometry, but that image measurement errors affect both slant and tilt seriously. In view of these results, it can not be claimed that the tilt is more reliably estimated from parallax than the slant. Despite the discovered sensitivity to image measurement errors, the tilt remains a very useful piece of information, in that it still specifies partial ordinal relations even when substantially degraded. We present a simple and efficient method to keep track of such partial information during all ongoing computation.;0;0;0;0;0;0;0
Parameter estimation variance of the single point active alignment method in optical see-through head mounted display calibration;Magnus Axholt,Matthew D. Cooper,Martin A. Skoglund,Stephen R. Ellis,Stephen D. O'Connell,Anders Ynnerman,;2011;2011 IEEE Virtual Reality Conference;22;https://doi.org/10.1109/VR.2011.5759432;The parameter estimation variance of the Single Point Active Alignment Method (SPAAM) is studied through an experiment where 11 subjects are instructed to create alignments using an Optical See-Through Head Mounted Display (OSTHMD) such that three separate correspondence point distributions are acquired. Modeling the OSTHMD and the subject's dominant eye as a pinhole camera, findings show that a correspondence point distribution well distributed along the user's line of sight yields less variant parameter estimates. The estimated eye point location is studied in particular detail. The findings of the experiment are complemented with simulated data which show that image plane orientation is sensitive to the number of correspondence points. The simulated data also illustrates some interesting properties on the numerical stability of the calibration problem as a function of alignment noise, number of correspondence points, and correspondence point distribution.;0;0;0;0;0;0;0
Pavement Crack Detection on BEV Based on Attention-Unet;Jia Zhang,Na Chen,Jiangtao Peng,Feng Cui,;2022;2022 IEEE 2nd International Conference on Digital Twins and Parallel Intelligence (DTPI);0;https://doi.org/10.1109/DTPI55838.2022.9998932;Identifying and detecting pavement cracks quickly and accurately for traffic safety is one of the important problems in the field of automatic driving. This study presents a framework of crack detection on BEV (Bird's Eye View). Firstly, based on the binocular parallax information, the captured road image is transformed from perspective to BEV as the input of the network. The Unet with attention mechanism is used to selectively fuse the deep and shallow features to identify the cracks on the pavement. In addition, further processing is performed according to the results of crack detection. The results help judge the quality of the pavement and provide a basis for the measurement of crack width in the direction of normal vector, laying a foundation for subsequent application. The test shows the method has high detection accuracy and is suitable for complex pavement conditions.;0;0;0;0;0;0;0
Perceptually Reduced Crosstalk by Modifying Binocular Images Depending on Dominant Eye;Jong-Man Kim,Seung-Ryul Kim,Minkoo Kim,Joohwan Kim,Seung-Woo Lee,;2015;Journal of Display Technology;1;https://doi.org/10.1109/JDT.2015.2399506;We propose a new method that uses ocular dominance to reduce perceived crosstalk in autostereoscopic 3D displays. When one increases the brightness of dominant eye's view while decreasing the other, the crosstalk effectively decreases for the dominant eye but increases for the other. We hypothesize that such manipulation would reduce the perceived crosstalk because the brain's visual processing relies more on the dominant eye than the other. We verify our hypothesis through a psychophysical experiment.;0;0;0;0;0;0;0
Phase-amplitude modulation during critical period plasticity in mouse visual cortex;Anju Malik,Abdelrahman B. M. Eldaly,Leanne Lai-Hang Chan,;2021;2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC);0;https://doi.org/10.1109/EMBC46164.2021.9629593;Much of our understanding of experience-dependent plasticity originates from the level of single cells and synapses through the well-established techniques of whole-cell recording and calcium imaging. The study of cortical plasticity of neural oscillatory networks remains largely unexplored. Cross-frequency coupling has become an emerging tool to study the underlying mechanisms for synchronization and interaction between local and global processes of cortical networks. The phase of low-frequency oscillations modulates the amplitude of high-frequency oscillations through a phase-amplitude coupling. Recent studies found that gamma-band oscillations associate with critical period plasticity. The existence of such mechanisms in ocular dominance plasticity is yet to be fully demonstrated. In this study, in-vivo electrophysiological methods for recording local field potentials in the primary visual cortex (V1) of anesthetized mice are employed. Our results reveal the mechanisms of neuronal oscillatory activities for the experience-dependent plasticity of developing visual cortical circuits.;0;0;0;0;0;0;0
Present status of three-dimensional television research;T. Motoki,H. Isono,I. Yuyama,;1995;Proceedings of the IEEE;58;https://doi.org/10.1109/5.390119;Television that conveys real-time information has become an indispensable part of our lives. Its technology has advanced from the days of black-and-white sets to color models and to high-definition television (HDTV). HDTV has been contrived to provide the audience with greater immediate appeal such as sensation of reality and power than the current TV system does and its worldwide applications are expected to continue to grow. Real world information which we obtain with our eyes is three-dimensional. It is reasonable therefore, that we humans want an imaging system that produces pictures that are as natural and real as things we see and experience every day. Three-dimensional television (3DTV) is a very promising approach expected to satisfy such wishes. As television technology matures and HDTV produces pictures as clear as movies, 3DTV is now capable of providing real-time stereoscopic pictures with high resolution. This paper outlines the studies that have been carried out about 3DTV as a post-HDTV system. The themes of the paper are focused to such topics as human factors in relation to binocular parallax, camera and display systems, and bandwidth reduction technology.<>;0;0;0;0;0;0;0
Q-learning Based Obstacle Avoidance Control of Autonomous Underwater Vehicle with Binocular Vision;Liang Zhang,Jing Yan,Xian Yang,Xiaoyuan Luo,;2022;2022 41st Chinese Control Conference (CCC);0;https://doi.org/10.23919/CCC55666.2022.9902381;Autonomous Underwater Vehicle (AUV) is widely used in various marine tasks, in which the autonomous obstacle avoidance function is the key technology to achieve autonomous motion such as path planning and trajectory tracking. Autonomous obstacle avoidance requires AUV to effectively detect obstacle information and select the optimal control strategy through autonomous judgment to achieve the obstacle avoidance function. However the ocean environment is very complex, full of uncertainty and danger, the underwater information obtained by using acoustic detection technology is very limited, which makes the control of underwater robot very difficult. To address this problem, this paper proposes a method for obstacle avoidance by binocular visual parallax control (BVPC) technique. In addition, the motion control of the robot is realized by Q learning (QL). In particular, the control strategy can be applied to different underwater unknown scenarios instead of a specific one, improving the wide applicability of this control method. Finally, the effectiveness of the proposed scheme is verified by simulation.;0;0;0;0;0;0;0
Quality Prediction of Asymmetrically Distorted Stereoscopic 3D Images;Jiheng Wang,Abdul Rehman,Kai Zeng,Shiqi Wang,Zhou Wang,;2015;IEEE Transactions on Image Processing;130;https://doi.org/10.1109/TIP.2015.2446942;Objective quality assessment of distorted stereoscopic images is a challenging problem, especially when the distortions in the left and right views are asymmetric. Existing studies suggest that simply averaging the quality of the left and right views well predicts the quality of symmetrically distorted stereoscopic images, but generates substantial prediction bias when applied to asymmetrically distorted stereoscopic images. In this paper, we first build a database that contains both single-view and symmetrically and asymmetrically distorted stereoscopic images. We then carry out a subjective test, where we find that the quality prediction bias of the asymmetrically distorted images could lean toward opposite directions (overestimate or underestimate), depending on the distortion types and levels. Our subjective test also suggests that eye dominance effect does not have strong impact on the visual quality decisions of stereoscopic images. Furthermore, we develop an information content and divisive normalization-based pooling scheme that improves upon structural similarity in estimating the quality of single-view images. Finally, we propose a binocular rivalry-inspired multi-scale model to predict the quality of stereoscopic images from that of the single-view images. Our results show that the proposed model, without explicitly identifying image distortion types, successfully eliminates the prediction bias, leading to significantly improved quality prediction of the stereoscopic images.;0;0;0;0;0;0;0
Reaction-diffusion based model to develop binocular simple cells in visual cortex along with cortical maps;M Sultan M Siddiqui,Basabi Bhaumik,;2010;The 2010 International Joint Conference on Neural Networks (IJCNN);2;https://doi.org/10.1109/IJCNN.2010.5596541;"In this paper we present reaction-diffusion based two eye model to develop disparity selective binocular simple cell receptive fields (RFs) in layer IV of cat visual cortex (V1). Pre-eye opening environment is used for development of binocular simple cell RFs. Our model also supports post-eye opening period development of binocular simple cell RFs. Developed binocular simple cells, left and right receptive fields have: (i) matched preferred orientations (interocular difference in preferred orientations of both eyes are within ±20° (µ=13.5°, S.D=12.7°)), (ii) matched spatial frequencies (with mean difference=µ=0.007, S.D=0.0617), (iii) varying ocular dominance, and (iv) position and phase disparities, with slight positive correlation (r=0.3); which conforms to biological findings [1–4]. Developed orientation and ocular dominance (OD) maps have OD peaks lying on/near the pinwheel singularities of the orientation map, which is in congruence with experimental findings by Crair et al. [5].";0;0;0;0;0;0;0
Relating Eye Dominance to Neurochemistry in the Human Visual Cortex Using Ultra High Field 7-Tesla MR Spectroscopy;I. Betina Ip,Claudia Lunghi,Uzay E. Emir,Andrew J. Parker,Holly Bridge,;2019;2019 International Conference on 3D Immersion (IC3D);0;https://doi.org/10.1109/IC3D48390.2019.8976001;Although our view of the world looks singular, it is combined from each eye's separate retinal image. If the balanced input between eyes is disrupted during early childhood, visual acuity and stereoscopic depth perception are impaired. This is because one eye dominates over the other, causing a neurological condition called `amblyopia' [1]. In the normal, healthy visual system, the balance between eyes can be determined using various methods to provide a measure of `eye dominance'. Eye dominance is the preference for using image from one eye over another [2], suggesting that the visual system applies different weights upon their input. Hence, eye dominance is relevant for understanding the mechanisms underlying binocular vision. As an investigative strategy to understand the binocular visual system in health in disease, we want to characterize eye dominance in the normal visual system. This information can then be used to serve as a baseline to compare to extreme eye dominance in `amblyopia'. Specifically, we ask to which degree variations in eye dominance are related to visual cortex concentrations of major excitatory neurotransmitter and metabolite glutamate (`Glu') and inhibitory neurotransmitter γ-aminobutyric acid (`GABA'). Their relationship is formalised as the `Glu/GABA' ratio. 13 participants took part in a 1-h psychophysical experiment to quantify eye dominance and a separate 1.5-h 7-Tesla MRI brain scan to measure hemodynamic and neurochemical responses during visual stimulation. The degree of eye dominance was predicted by the inter-ocular difference in V1 Glu/GABA balance. Stronger eye dominance correlated with an increase in inhibition during dominant relative to non-dominant eye viewing (r = -0.647, p = 0.023). In contrast the hemodynamic response, measured with functional magnetic resonance imaging, did not correlate with eye dominance. Our findings suggest that normally occurring eye dominance is associated with the balance of neurochemicals in the early visual cortex.;0;0;0;0;0;0;0
Repeated vergence adaptation causes the decline of visual functions in watching stereoscopic television;M. Emoto,T. Niida,F. Okano,;2005;Journal of Display Technology;160;https://doi.org/10.1109/JDT.2005.858938;"To evaluate visual fatigue when viewing stereoscopic TV, a technology expected to become the broadcasting display system of the future. Wide public acceptance of stereoscopic TV awaits resolution of many issues, including visual fatigue on viewing TV images. Visual fatigue was induced using a visual function simulator, consisting of prism and lens optical systems, while viewing stereoscopic TV. We assessed subject visual fatigue through subjective reports of symptoms and by the changes in visual functions. These functions included: viewer B [Js fusional break point, recovery point, accommodation step response, and visual evoked cortical potentials (VECP)]. Significant changes of some visual functions were found after watching simulated stereoscopic TV when the vergence load was heavy or when it changed over time; relative vergence limits decreased and the latency of VECP increased after watching, reflecting visual fatigue. After subjects rested, relative vergence limits recovered to pre-viewing levels. Our findings lead us to conclude that, aside from excessive horizontal binocular parallax, discontinuous changes in parallax is also a major factor that contributes to visual fatigue in the viewing of stereoscopic images. It also causes a decreased range of relative vergence, accommodation response, and a delay in the P100 latency of VECP.";0;0;0;0;0;0;0
Research on AGV Navigation System Based on Binocular Vision;Changsheng Ai,Dunyang Geng,Zhengguang Qi,Lei Zheng,Zhiquan Feng,;2021;2021 IEEE International Conference on Real-time Computing and Robotics (RCAR);1;https://doi.org/10.1109/RCAR52367.2021.9517359;Aiming at the problems that the traditional single sensor of AGV cannot meet the indoor and outdoor operating conditions and the cost of multiple sensors is too high, this paper proposes an AGV navigation method using binocular camera. The binocular camera is used to identify the lane line and obtain the pose deviation of the vehicle body relative to the lane line, and then track the path. The depth information of obstacles is obtained by using binocular parallax principle, and then the vehicle body is protected safely. The pose deviation of the vehicle body relative to the lane line obtained by the proposed binocular camera was verified by experiments. The experimental results show that the pose information obtained by the binocular camera is reliable and stable, and meets the requirements of AGV navigation. The use of binocular vision AGV navigation system, can be suitable for navigation.;0;0;0;0;0;0;0
Research on Binocular Stereo Vision Ranging Based on Improved YOLOv5s;Pengwei Zhang,Zhenyu Liu,;2023;2023 5th International Conference on Intelligent Control, Measurement and Signal Processing (ICMSP);0;https://doi.org/10.1109/ICMSP58539.2023.10170936;In order to accurately obtain the distance information of the target, a target detection and distance measurement method based on an improved YOLOv5s model and binocular stereo vision fusion is proposed. First, the attention mechanism is introduced into the YOLOv5s model, and the comparison experiments show that the introduction of the ECA module improves the accuracy rate by 2.1%. Furthermore, by adding the SGBM-based binocular distance measurement algorithm to the YOLOv5s model, the distance of the target is calculated and given using the binocular parallax information during target detection. The experimental results show that the method measures the distance with less error, which provides technical support for many low-cost, non-contact ranging scenarios.;0;0;0;0;0;0;0
Research on TOF camera-based guided binocular fusion technology;Siyuan Gao,Lichao Fang,Xintian Cui,;2021;2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer (ICFTIC);1;https://doi.org/10.1109/ICFTIC54370.2021.9647410;As environment perception becomes increasingly necessary in human-computer interaction tasks, researchers are applying it to specific tasks, such as depth-of-field measurements by depth cameras. In order to improve the accuracy of depth information in-depth maps obtained by current depth cameras, this paper uses the complementary properties of TOF technology and binocular stereo vision technology to fuse TOF and binocular technology, guiding binocular stereo matching by matching TOF parallax maps with binocular parallax map feature points, and discussing the process of guided matching. Among them, the better Census matching algorithm is selected for experiments in the stereo matching process. The binocular matching after TOF guidance by this method significantly improves the matching time and the quality of the matched parallax map.;0;0;0;0;0;0;0
Research on key technology of geographical scene based on binocular stereoscopic vision;Yu Hu,Ka Zhang,Yehua Sheng,Jian Li,Yongzhi Wang,Pingfei Zhang,;2010;The 2nd International Conference on Information Science and Engineering;0;https://doi.org/10.1109/ICISE.2010.5691519;This paper researched the key issues of the true 3D geographic scene visualization based on the binocular vision. Firstly the essential stereoscopic theories such as the formation of stereoscopic perception are introduced in detail, and several binocular projection models to calculate stereo pairs are given. Secondly, Based on discussion of stereoscopic theory and related experiments, this paper gives an algorithm of binocular parallax model. In the end, by analyzing geographic scene mesh file formats and introducing 3D graphics API, the stereoscopic software rendering geographic scenes in stereo pairs is developed on the parallax 3D-LCD display. That just provides a practical approach for true 3D visualization of virtual geography environment.;0;0;0;0;0;0;0
Retinal Layer Segmentation in Optical Coherence Tomography Images;Bashir Isa Dodo,Yongmin Li,Djibril Kaba,Xiaohui Liu,;2019;IEEE Access;13;https://doi.org/10.1109/ACCESS.2019.2947761;The four major causes of blindness are age-related diseases, out of which three affects the retina. These diseases, i.e., glaucoma, diabetic retinopathy, and age-related macular degeneration, require life-long treatment and cause irreversible blindness. Conversely, early diagnosis has been shown to curtail or prevent blindness and visual impairments. A critical element of the clinical diagnosis is the analysis of individual retinal layer properties, as the manifestation of the dominant eye diseases has been shown to correlate with structural changes to the retinal layers. Regrettably, manual segmentation is dependent on the ophthalmologist's level of expertise, and currently becoming impractical due to advancement in imaging modalities. Inherently, much research on computer-aided diagnostic methods is conducted to aid in extracting useful layer information from these images, which were inaccessible without these techniques. However, speckle noise and intensity inhomogeneity remain a challenge with a detrimental effect on the performance of automated methods. In this paper, we propose a method comprising of fuzzy image processing techniques and graph-cut methods to robustly segment optical coherence tomography (OCT) into five (5) distinct layers. Notably, the method establishes a specific region of interest to suppress the interference of speckle noise, while Fuzzy C-means is utilized to build data terms for better integration into the continuous max-flow to handle inhomogeneity. The method is evaluated on 225 OCT B-scan images, and promising experimental results were achieved. The method will allow for early diagnosis of major eye diseases by providing the basic, yet critical layer information necessary for an effective eye examination.;0;0;0;0;0;0;0
Simulated optical imaging of orientation preference in a model of V1;J. Wielaard,P. Sajda,;2003;First International IEEE EMBS Conference on Neural Engineering, 2003. Conference Proceedings.;1;https://doi.org/10.1109/CNE.2003.1196872;Optical imaging studies have played an important role in mapping the orientation selectivity and ocular dominance of neurons across an extended area of primary visual cortex (V1). Such studies have produced images with a more or less smooth and regular spatial distribution of relevant neuronal response properties. This is in spite of the fact that results from electrophysiological recordings, though limited in their number and spatial distribution, show significant scatter/variability in the relevant response properties of nearby neurons. We present a simulation of the optical imaging experiments of ocular dominance and orientation selectivity using a computational model of the primary visual cortex. The simulations assume that the optical imaging signal is proportional to the averaged response of neighboring neurons. The model faithfully reproduces ocular dominance columns and orientation pinwheels in the presence of realistic scatter of single cell preferred responses. In addition,we find the simulated optical imaging of orientation pinwheels to be remarkably robust, with the pinwheel structure maintained up to an addition of /spl plusmn/60 degrees of random scatter in the orientation preference of single cells. Our results suggest that an optical imaging result does not necessarily, by itself, provide any obvious upper bound for the scatter of the underlying neuronal response properties on local scales.;0;0;0;0;0;0;0
Stereo Express of Spatial Geographical Entity;An Jing,Shi Ruizhi,Wen Jianlong,;2008;2008 International Conference on Computer Science and Software Engineering;1;https://doi.org/10.1109/CSSE.2008.1006;"Several method of describe the spatial geographical entity. A sort of method is true scenery model, mainly depend on build a sand table to simulate the three-dimension shape of praxis scenery; One method is general plane, for example, rely on contour line, color gradient and hill shading, the map looker can feel the fluctuant terrain from the tradition plane map; dummy simulation is also a important method, now the technology of computer simulation can reappearance the three-dimension physiognomy and scene on the screen more realer; Another is the method of plane parallax, people's eyes can separate see the image maps which have definite parallax by the equipment of 3D glasses, HMD, lenticular screen etc, and the vision amalgamation in the brain form third dimension. These theories, characteristic of method and its application on express spatial geographical entity are introduced in this paper.";0;0;0;0;0;0;0
Stereoscopic Video Synthesis from a Monocular Video;Guofeng Zhang,Wei Hua,Xueying Qin,Tien-Tsin Wong,Hujun Bao,;2007;IEEE Transactions on Visualization and Computer Graphics;33;https://doi.org/10.1109/TVCG.2007.1032;This paper presents an automatic and robust approach to synthesize stereoscopic videos from ordinary monocular videos acquired by commodity video cameras. Instead of recovering the depth map, the proposed method synthesizes the binocular parallax in stereoscopic video directly from the motion parallax in monocular video, The synthesis is formulated as an optimization problem via introducing a cost function of the stereoscopic effects, the similarity, and the smoothness constraints. The optimization selects the most suitable frames in the input video for generating the stereoscopic video frames. With the optimized selection, convincing and smooth stereoscopic video can be synthesized even by simple constant-depth warping. No user interaction is required. We demonstrate the visually plausible results obtained given the input clips acquired by ordinary handheld video camera.;0;0;0;0;0;0;0
Study of binocular parallax estimation algorithms with different focal lengths;Mingde Zheng,Ziliang Wang,Heng Li,Jingyu Lu,;2023;2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA);0;https://doi.org/10.1109/EEBDA56825.2023.10090658;"Existing binocular parallax estimation algorithms all use standard stereo cameras, which are unable to achieve high definition for monitoring both near and far objects due to the camera's own parameters. In order to solve this problem, a parallax estimation method is proposed for images taken by cameras with different focal lengths, which can directly calculate parallax maps for near and far views. A calibrated stereo correction method is proposed to parameterise the binocular image scaling for direct image correction at different focal lengths; the monocular portion of the results is calibrated by comparing the parallax results in the binocular range and introducing monocular parallax correction parameters. Experimental results on the Middlebury Stereo public dataset, which was used to simulate images of different focal lengths, show that the proposed parallax estimation algorithm was able to generate both far-field and near-field parallax maps with an avgerr of 8.33%, which is significantly better than the monocular parallax estimation method.";0;0;0;0;0;0;0
Subjective study on asymmetric stereoscopic video with low-pass filtered slices;Maryam Azimi,Sima Valizadeh,Xiaokang Li,Lino E. Coria,Panos Nasiopoulos,;2012;2012 International Conference on Computing, Networking and Communications (ICNC);7;https://doi.org/10.1109/ICCNC.2012.6167516;This paper proposes a new method for asymmetric filtering of stereoscopic video. In traditional asymmetric stereoscopic video coding, the quality of one of the views is reduced while the other view is of original quality. However, this approach is not fair for people with one dominant eye. We propose to address this problem by reducing the quality of horizontal slices in both views. In our approach, we applied low-pass filtering to slices of both views while the corresponding slice in the other view is untouched. Subjective tests show that the quality, sharpness and depth of the low-passed filtered stereo video are close to the original one. We tested a different number of horizontal slices and various levels of filtering for two representative video sequences. Results show that low-pass filtering of the horizontal slices of both views with smoothing on the slice edges is an effective technique for asymmetric stereoscopic videos.;0;0;0;0;0;0;0
Target tracking and measuring based on binocular vision;Bo Li,Wei Xie,;2013;2013 IEEE Third International Conference on Information Science and Technology (ICIST);2;https://doi.org/10.1109/ICIST.2013.6747797;Vision system which can be used for real-time tracking and measuring of moving target is very important in robot soccer match. Based on DSP embedded vision subsystem, this paper proposes a method to measure the binocular distance based on binocular parallax between two images' color. First, camera's intrinsic parameters can be determined by calculating the R component of the pixels' color of the image in the experiment of camera calibration. Then image segment is used in real-time capture of the target's images, and the binocular parallax and the world coordinates of target are calculated. Then the target can be located by regional color matching method. The results of the experiments show that this algorithm can detect and locate the target commendably. It sets up a platform for further research which can supply plenteous information for strategy system and tracking target.;0;0;0;0;0;0;0
The Differences Between Toed-in Camera Configurations and Parallel Camera Configurations in Shooting Stereoscopic Images;H. Yamanoue,;2006;2006 IEEE International Conference on Multimedia and Expo;17;https://doi.org/10.1109/ICME.2006.262877;A fundamental element of stereoscopic image production is to geometrically analyze the conversion from real space to stereoscopic images by binocular parallax under various shooting and viewing conditions. This paper reports on this analysis, particularly on the setting of the optical axes of 3D cameras, which has received little attention in the past. The parallel camera configuration maintains linearity during the conversion from real space to stereoscopic images. But the toed-in camera configuration often can not maintain linearity during the conversion from real space to stereoscopic images;0;0;0;0;0;0;0
The Joint Development of Orientation and Ocular Dominance: Role of Constraints;Christian Piepenbrock,Helge Ritter,Klaus Obermayer,;1997;Neural Computation;1;https://doi.org/10.1162/neco.1997.9.5.959;"Correlation-based learning (CBL) has been suggested as the mechanism that underlies the development of simple-cell receptive fields in the primary visual cortex of cats, including orientation preference (OR) and ocular dominance (OD) (Linsker, 1986; Miller, Keller, & Stryker, 1989). CBL has been applied successfully to the development of OR and OD individually (Miller, Keller, & Stryker, 1989; Miller, 1994; Miyashita & Tanaka, 1991; Erwin, Obermayer, & Schulten, 1995), but the conditions for their joint development have not been studied (but see Erwin & Miller, 1995, for independent work on the same question) in contrast to competitive Hebbian models (Obermayer, Blasdel, & Schulten, 1992). In this article, we provide insight into why this has been the case: OR and OD decouple in symmetric CBL models, and a joint development of OR and OD is possible only in a parameter regime that depends on nonlinear mechanisms.";0;0;0;0;0;0;0
The Relation between Size Distortion and Shooting Conditions for Stereoscopic Images;Hirokazu Yamanoue,;1997;SMPTE Journal;21;https://doi.org/10.5594/J00566;Research on shooting methods of 3-D program production for natural and fatigue-free 3-D images is under way. Toed-in and parallel camera configurations are available for shooting 3-D programs. The former is usually used because shooting and viewing conditions can be easily set to get a desired 3-D design. It has been shown, however, that this camera configuration brings about the inconsistency between depth information by lens perspective and by binocular parallax, and that this inconsistency leads to the size distortion called the puppet theater effect. This effect describes the tendency of objects in 3-D images to look unnaturally small. On the contrary, the parallel camera configuration does not cause such inconsistency under the specific shooting and viewing conditions called the orthostereoscopic condition. The possibilities of representation in 3-D images using this method are discussed in this paper.;0;0;0;0;0;0;0
The Role of Constraints in Hebbian Learning;Kenneth D. Miller,David J. C. MacKay,;1994;Neural Computation;16;https://doi.org/10.1162/neco.1994.6.1.100;"Models of unsupervised, correlation-based (Hebbian) synaptic plasticity are typically unstable: either all synapses grow until each reaches the maximum allowed strength, or all synapses decay to zero strength. A common method of avoiding these outcomes is to use a constraint that conserves or limits the total synaptic strength over a cell. We study the dynamic effects of such constraints. Two methods of enforcing a constraint are distinguished, multiplicative and subtractive. For otherwise linear learning rules, multiplicative enforcement of a constraint results in dynamics that converge to the principal eigenvector of the operator determining unconstrained synaptic development. Subtractive enforcement, in contrast, typically leads to a final state in which almost all synaptic strengths reach either the maximum or minimum allowed value. This final state is often dominated by weight configurations other than the principal eigenvector of the unconstrained operator. Multiplicative enforcement yields a “graded” receptive field in which most mutually correlated inputs are represented, whereas subtractive enforcement yields a receptive field that is “sharpened” to a subset of maximally correlated inputs. If two equivalent input populations (e.g., two eyes) innervate a common target, multiplicative enforcement prevents their segregation (ocular dominance segregation) when the two populations are weakly correlated; whereas subtractive enforcement allows segregation under these circumstances. These results may be used to understand constraints both over output cells and over input cells. A variety of rules that can implement constrained dynamics are discussed.";0;0;0;0;0;0;0
The effects of depth warping on perceived acceleration in stereoscopic animation;Sidrah Laldin,Laurie M. Wilcox,Robert S. Allison,;2016;2016 International Conference on 3D Imaging (IC3D);0;https://doi.org/10.1109/IC3D.2016.7823446;Stereoscopic media produce the sensation of depth through differences between the images presented to the two eyes. These differences arise from binocular parallax which in turn is caused by the separation of the cameras used to capture the scene. Creators of stereoscopic media face the challenge of depicting compelling depth while restricting the amount of parallax to a comfortable range. To address this tradeoff, stereoscopic warping or depth adjustment algorithms are used in the post-production process to selectively increase or decrease the depth in specific regions. This process modifies the image's depth-to-parallax mapping to suit the desired parallax range. As the depth is adjusted using non-linear parallax re-mapping functions, the geometric stereoscopic space is distorted. In addition, the relative expansion or compression of stereoscopic space should theoretically affect the perceived acceleration of an object passing through that region. Here we evaluate this prediction and determine if stereoscopic warping affects viewers' perception of acceleration. Observers judged the perceived acceleration of an approaching object (a toy helicopter) moving in depth through a complex stereoscopic 3D scene. The helicopter flew at one of two altitudes, either ground level or camera level. For each altitude, stereoscopic animations were produced under three depth re-mapping conditions (i) compressive, (ii) expansive, and (iii) zero (no re-mapping) for a total of six test conditions. We predicted that expansive depth re-mapping would produce a bias toward perceiving deceleration of the approaching helicopter, while compressive depth remapping would result in a bias toward seeing acceleration. However, there were no significant differences in the amount or direction of bias between the re-mapping conditions. We did find a significant effect of the helicopter altitude, such that there was little bias in acceleration judgements when the helicopter moved at ground level but a significant bias towards reporting acceleration when the helicopter moved at camera level. This result is consistent with the proposal that observers can make use of additional monocular (2D) cues in the ground level condition to improve their acceleration estimates. The lack of an effect of depth re-mapping suggests that viewers have considerable tolerance to depth distortions resulting from stereoscopic post-processing. These results have important implications for effective post-production and quality assurance for stereoscopic 3D content creation.;0;0;0;0;0;0;0
The role of activity in corpus callosum development in the visual cortex;T. Hely,;1999;1999 Ninth International Conference on Artificial Neural Networks ICANN 99. (Conf. Publ. No. 470);0;https://doi.org/10.1049/cp:19991144;Many previous models have explained how ocular dominance- and orientation selective columns could develop in the visual cortex. However, few models have investigated the topographic arrangement of interhemispheric connections between primary visual areas. A model of the development of corpus callosum connections in cat visual cortex was presented by Hely (1999). The model showed how the observed hour-glass pattern of callosal receptive field (RF) positions arises as a consequence of the retinotopic mapping onto the cortex. In the cat, callosal connections only form between cells with visual field RFs located close to the vertical meridian. In contrast in rat visual cortex, callosal connections also form between cells with RFs in the peripheral visual field. This cannot be accounted for using a Hebbian rule based on spatial information alone. The current generic model of primary visual cortex was extended by including optic-flow/motion information. This extra input enabled cells with peripheral RFs fields in the medial cortex to make connections to the opposite hemisphere. The results from the model suggest that in some species motion information may affect the development of connections in primary visual cortex.;0;0;0;0;0;0;0
Three-Dimensional TV Using Holographic Stereogram;Koki Sato,Masataka Tozuka,Makoto Ohki,Kunihiko Takano,;2010;2010 IEEE/ACIS 9th International Conference on Computer and Information Science;0;https://doi.org/10.1109/ICIS.2010.29;Computer holographic stereogram (CHS) is useful for holographic 3D TV because it is constructed from the multi camera horizontal viewpoint plane images and is compatible to the multi holographic stereogram image. Each hologram is recorded as a slit hologram (element hologram) but total viewing area and the number of the element holograms have been limited to some extent by the size and the resolution points of LCD panel. Therefore we used two LCDs for making CHS and deposited them horizontally and increased the viewing points to two times and extend the display area to satisfy the binocular parallax. We considered how viewing area becomes extended. We consider how we could improve the characteriostics of the images of CHS. We got moving images with this system using web-camera and considered the real time calculation about the hologram 3D-TV.;0;0;0;0;0;0;0
Three-dimensional Reconstruction of Retinal Blood Vessels based on Binocular Vision;Chao-liang Wu,Zhi-jin Lv,Hua-zhu Liu,Xiao-fang Zhao,;2022;2022 14th International Conference on Computational Intelligence and Communication Networks (CICN);0;https://doi.org/10.1109/CICN56167.2022.10008256;Due to the limited perception ability of the naked eye, it is difficult to accurately locate the micro scale retinal vessels, which is easy to cause organ damage in the process of surgery. Therefore, the retinal vascular reconstruction method based on binocular stereo vision is studied. Firstly, build a binocular vision detection system and then calibrate and correct the system. Secondly, filter and segment the collected 3D printed eyeball blood vessel model image, and calculate the parallax and depth map by constructing the error energy function. After that, the high-precision 3D point cloud model can be obtained. Finally, the error analysis of three-dimensional point cloud is carried out by binocular parallax principle. The experimental results show that this method can control the error within 0.5 mm and meet the requirements of retinal vascular surgery.;0;0;0;0;0;0;0
Three-dimensional imaging methods based on multiview images;J.-Y. Son,B. Javidi,;2005;Journal of Display Technology;154;https://doi.org/10.1109/JDT.2005.853354;Three-dimensional imaging methods, based on parallaxes as their depth cues, can be classified into the stereoscopic providing binocular parallax only, and multiview providing both binocular and motion parallaxes. In these methods, the parallaxes are provided by creating a viewing zone with use of either a special optical eyeglasses or a special optical plate as their viewing zone-forming optics. For the stereoscopic image generations, either the eyeglasses or the optical plate can be employed, but for the multiview the optical plate or the eyeglasses with a tracking device. The stereoscopic image pair and the multiview images are presented either simultaneously or as a time sequence with use of projectors or display panels. For the case of multiview images, they can also be presented as two images at a time according to the viewer's movements. The presence of the viewing zone-forming optics often causes undesirable problems, such as appearance of moire/spl acute/ fringes, image quality deterioration, depth reversion, limiting viewing regions, low image brightness, image blurring, and inconveniences of wearing.;0;0;0;0;0;0;0
Three-dimensional perception in multi-slit vision for public display;Hideyuki Ando,Taro Maeda,Yohei Miyazaki,Junji Watanabe,;2013;2013 IEEE Virtual Reality (VR);0;https://doi.org/10.1109/VR.2013.6549430;As a low-cost information display in public spaces, we achieved a multi-slit display by the arrangement of LED columns. Multi-slits visually present an image pattern through columns of slits that are arranged several spaces wide. They cannot be perceived image by stop patterns, but they can be perceived by scroll patterns. In this paper, we experimentally show that stereoscopic vision is possible by presenting binocular parallax images that impart the beam direction from slits.;0;0;0;0;0;0;0
Topographic Receptive Fields and Patterned Lateral Interaction in a Self-Organizing Model of the Primary Visual Cortex;Joseph Sirosh,Risto Miikkulainen,;1997;Neural Computation;11;https://doi.org/10.1162/neco.1997.9.3.577;This article presents a self-organizing neural network model for the simultaneous and cooperative development of topographic receptive fields and lateral interactions in cortical maps. Both afferent and lateral connections adapt by the same Hebbian mechanism in a purely local and unsupervised learning process. Afferent input weights of each neuron self organize into hill-shaped profiles, receptive fields organize topographically across the network, and unique lateral interaction profiles develop for each neuron. The model demonstrates how patterned lateral connections develop based on correlated activity and explains why lateral connection patterns closely follow receptive field properties such as ocular dominance.;0;0;0;0;0;0;0
Topography and ocular dominance can arise from distributed patterns of activity;G. Goodhill,;1991;IJCNN-91-Seattle International Joint Conference on Neural Networks;1;https://doi.org/10.1109/IJCNN.1991.155407;The author describes a novel activity-based model which uses a simple competitive mechanism to form a topographic map and ocular dominance stripes simultaneously. The model does not attempt to take into account all that is known about the development of the visual system. Rather, its aim is to show how simple Hebbian learning combined with a suitable weight normalization rule can lead to the development of these mappings. The model forms an appropriate mapping when presented with distributed patterns of activity in the retina. This is much closer to biological reality than the activity regime used in previous models. The author considers input consisting of random noise filtered through a Gaussain as a first step towards investigating the effects of retinal correlations on receptive field and map development in this model. Simulation results on the monocular and binocular cases are presented.<>;0;0;0;0;0;0;0
Topological ordering in neural nets with weak nearest neighbour interactions;V. Tereshko,;2001;IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222);0;https://doi.org/10.1109/IJCNN.2001.939035;We show that topological order can be developed in networks with weak nearest neighbour interactions through the controlled smoothing of their energy landscapes. The energy landscape deformations are modelled by deterministic annealing. In cortical mappings, we use a combination of elastic and nearest neighbour lateral interactions, which helps to control the cortex pattern. Utilizing only nearest neighbour lateral interactions in the visual cortex mappings, one obtains the simultaneous formation of retinotopy and ocular dominance stripes where regular clusters of cortical cells are associated with either left or right eyes.;0;0;0;0;0;0;0
Trial operation of a cloud service-based three-dimensional virtual reality tele-rehabilitation system for stroke patients;Norio Kato,Toshiaki Tanaka,Shunichi Sugihara,Koichi Shimizu,Nobuki Kudo,;2016;2016 11th International Conference on Computer Science & Education (ICCSE);3;https://doi.org/10.1109/ICCSE.2016.7581595;We developed a tele-rehabilitation system to improve community rehabilitation for patients who are discharged early from hospital. The developed tele-rehabilitation system consists of devices designed to reduce the physical and economic burden on users while promoting optimum user movement. A Backend-as-a-Service cloud computing service was used for the communication between terminals. A non-contact sensor, Kinect, was used to measure movement. In addition, we used a three-dimensional (3D) display to present 3D images using binocular parallax, to encourage smooth movement of patients. We used this system for stroke patients and found improvements in task-performance time, smoothness of movements, and range of motion in all patients. No major issues occurred during the tele-rehabilitation. These results demonstrated the high operability and efficacy of our cloud service-based 3D virtual reality tele-rehabilitation system.;0;0;0;0;0;0;0
Using 3D for rebalancing the visual system of amblyopic children;Angelo Gargantini,Mariella Bana,Flavia Fabiani,;2011;2011 International Conference on Virtual Rehabilitation;10;https://doi.org/10.1109/ICVR.2011.5971825;Amblyopia or “lazy” eye is a disorder of the visual system that causes poor vision in an eye that is otherwise physically normal, and it affects 2–3% of the population, which equates to conservatively around 10 million people under the age of 8 years worldwide. Amblyopia is a neurologically active process: the problem is caused by either no transmission or poor transmission of the visual stimulation through the optic nerve to the brain. With time, if no treatment is performed, the weak eye becomes even weaker and the other eye becomes dominant. Amblyopia is classically treated by clarifying the visual image with glasses, and patching (totally or partially) the dominant eye in order to force the use of the amblyopic eye. Patching suffers from several problems: it is unpopular, prolonged, and it can sometimes disrupts any residual fusion between the visions of the eyes. This results often in noncompliance with the therapy. Several alternatives have been introduced, including partial occlusion and vision rebalancing in which the image to the lazy eye is enhanced and the image to the good eye is penalized. We present how a 3D technology can be used to realize a system for vision rebalancing of video clips which exploits the stereo vision of the 3D system. This technology is relatively inexpensive, easy to use also in a domestic environment, with recreational activities enjoyable by the children, and easy to extend. We have implemented a prototype software system which processes a video and sends a penalized version to the good eye and an enhanced version to the lazy eye. We use a “framesever” for runtime video processing and several image filters and meta-filters to obtain the final video to be viewed by the patient. We argue for the viability of the proposed method in the treatment of amblyopic children.;0;0;0;0;0;0;0
Vergence Control of 2 DOF Pan-Tilt Binocular Cameras using a Log-Polar Representation of the Visual Cortex;A.X.J. Zhang,A.L.P. Tay,A. Saxena,;2006;The 2006 IEEE International Joint Conference on Neural Network Proceedings;2;https://doi.org/10.1109/IJCNN.2006.247001;This paper presents a neurologically inspired vergence control model that uses the optimization of the disparity error between interlaced cortical maps incident on the visual cortex (VC). This was inspired by the work of Hubel et al [4] where their investigations led to the discovery of the alternating organization of ocular dominance columns. While the implemented system consists of many modules including a simple component to function as the superior colliculus (SC) and modeling of attention traces from the Frontal Eye Fields (FEF) [5], this paper emphasizes the parts specific to using the log-polar maps on the visual cortex for vergence control. We explain how the log-polar image incident on the VC can be used successfully to determine the pan angle (saccade) to perform binocular vergence on points of in the scene. A discussion at the end of the paper highlights the significant differences between this system and the conventional object correspondence systems that require matching of specific object shapes. In this model, the cortically magnified VC image is used to match the entire image.;0;0;0;0;0;0;0
Vergence eye movements affected by 3D and 2D visual stimuli;Atsuhiko Iijima,Kosuke Matsuki,Ryota Imamura,Takehiko Bando,;2014;2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE);0;https://doi.org/10.1109/GCCE.2014.7031261;The function of depth perception may be related to the ability to perform vergence eye movements during the viewing of three-dimensional stereoscopic movies.;0;0;0;0;0;0;0
Viewing difficulties with head-mounted aids for mechanical assembly using nearby virtual objects;S.R. Ellis,F. Breant,B. Menges,R. Jacoby,B.D. Adelstein,;1996;Proceedings 1996 IEEE Conference on Emerging Technologies and Factory Automation. ETFA '96;0;https://doi.org/10.1109/ETFA.1996.573732;A head-mounted electronic haploscope was used in a see-through format to present computer generated, space-stabilized, nearby wire-like virtual objects to 18 subjects. The visual requirements of this task are very similar to those needed for use of a similar head-mounted information display under study as a primary information aid for manual aircraft wire harness assembly. The subjects visually traced the snake-like and rectilinear wire paths with a visual cursor before their dominant eye. Three subject groups used either monocular, biocular, or stereoscopic display conditions for 30 minutes of tracing. Pre and post tracing subjective viewing difficulties, disorientation, nausea, and measures of stereoscopic threshold, near and far horizontal and vertical phoria were made. Only the viewing difficulty, i.e. the eye and head/neck aches score, changed significantly. Biocular conditions were worse than either monocular or stereo which were nearly equivalent for this measure. The biocular viewing difficulties are likely due to conflicting looming and stereo disparity cues to vergence. Accordingly, special geometric design enhancements probably will be needed for biocular displays for work within arms reach.;0;0;0;0;0;0;0
Virtual Reality Video Game Paired with Physical Monocular Blurring as Accessible Therapy for Amblyopia;Ocean Hurd,Sri Kurniawan,Mircea Teodorescu,;2019;2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR);9;https://doi.org/10.1109/VR.2019.8797997;This paper discusses a virtual reality (VR) therapeutic video game for treatment of the neurological eye disorder, Amblyopia. Amblyopia is often referred to as lazy eye, and it entails weaker vision in one eye due to a poor connection between the eye and the brain. Until recently it was thought to be untreatable in adults, but new research has proven that with consistent therapy even adults can improve their Amblyopia, especially through perceptual learning and video games. Even so, therapy compliance remains low due to the fact that conventional therapies are perceived as either invasive, dull and/or boring. Our game aims to make Amblyopia therapy more immersive, enjoyable and playful. The game was perceived by our users to be a fun and accessible alternative, as it involves adhering a Bangerter foil (an opaque sticker) on a VR headset to blur vision in an Amblyopic person's dominant eye while having them playa VR video game. To perform well in the video game, their brain must adapt to rely on seeing with their weaker eye, thereby reforging that neurological connection. While testing our game, we also studied users behavior to investigate what visual and kinetic components were more effective therapeutically. Our findings generally show positive results, showing that visual acuity in adults increases with 45 minutes of therapy. Amblyopia has many negative symptoms including poor depth perception (nec-essary for daily activities such as driving), so this therapy could be life changing for adults with Amblyopia.;0;0;0;0;0;0;0
Visual 3D Perception of the Ski Course and Visibility Factors at Virtual Space;Vladimir Aleshin,Valery Afanasiev,Alexander Bobkov,Stanislav Klimenko,Vitaly Kuliev,Dmitry Novgorodtsev,;2011;2011 International Conference on Cyberworlds;6;https://doi.org/10.1109/CW.2011.16;Visual perception of 3D space is a major source of information for a person. The role of athlete's visual perception in movement behaviour is very important for adequate action in sport. Given the specialization of our team (virtual environment technology), we decided to investigate the impact of visual 3Dperception different parameters on the results of the virtual alpine skiing.;0;0;0;0;0;0;0
Volumetric Display for Augmented Reality;Ronald Sidharta,Atsushi Hiyama,Tomohiro Tanikawa,Michitaka Hirose,;2007;17th International Conference on Artificial Reality and Telexistence (ICAT 2007);1;https://doi.org/10.1109/ICAT.2007.17;In our previous paper, we proposed an augmented reality display based on the pepper's ghost configuration that was able to display two-dimensional images on different image plane at different physical depths. In this paper, we propose the next generation of the display. Our latest display is able to display images at different physical depths simultaneously, thus it is able to display virtual objects with real depth, binocular parallax and motion parallax without the use of special glasses. Using the pepper's ghost setup, we are able to display real world objects and virtual objects in the same space. Furthermore, since the rendered virtual objects have real physical depth, our system does not suffer from accommodation and convergence mismatch problem. We will describe the hardware setup, software system, and follow with two user evaluation experiments that evaluated the result of our system.;0;0;0;0;0;0;0
Weighted ensemble learning prediction for blind symmetrically distorted stereoscopic images;Da Pan,Ping Shi,Dixiu Zhong,Ming Hou,Zefeng Ying,Sizhe Fu,;2017;2017 4th International Conference on Systems and Informatics (ICSAI);2;https://doi.org/10.1109/ICSAI.2017.8248486;In recent years, deep learning has been largely applied to 2D image quality assessment (2D-IQA) but rarely to 3D image quality assessment (3D-IQA). In this paper, a new method for blind symmetrically distorted stereoscopic images quality assessment is proposed to utilize multiple features fusion in deep network to assess the left view and right view as an integration with no extra cost. According to binocular rivalry, a weighted ensemble learning network is developed for learning energy of dominant eye. We integrate these two networks into a full end-to-end network called a Weighted Ensemble Deep Quality Network (WEDQN). Our experimental results can demonstrate that the proposed method leads to significant improved quality prediction of symmetrically distorted stereoscopic images.;0;0;0;0;0;0;0
Withindows: A Framework for Transitional Desktop and Immersive User Interfaces;Alex Hill,Andrew Johnson,;2008;2008 IEEE Symposium on 3D User Interfaces;2;https://doi.org/10.1109/3DUI.2008.4476584;"The uniqueness of 3D interaction is often used to justify levels of user fatigue that are significantly higher than those of desktop systems. Object manipulation and symbolic manipulation techniques based strictly on first person perspective are also generally less efficient than their desktop counterparts. Instead of considering the two environments as distinct, we have focused on the idea that desktop applications will likely need to transition smoothly into full immersion through intermediate states. The Withindows framework uses image-plane selection and through- the-lens techniques in an attempt to smooth the movement of both traditional and immersive applications across transitional states such as desktop stereo and multi-display setups. We propose using a virtual cursor in the dominant eye and a reinforcing cursor in the non-dominant eye to avoid ambiguity problems that have discouraged the use of image-plane selection in stereo. We show how image-plane selection resolves non-linear control-display relationships inherent in some approaches to desktop stereo. When combined with through-the-lens techniques, image-plane selection allows immersive viewpoint management and 2&‌#xBD;D object manipulation techniques analogous to those on the desktop. This approach resolves global search and scaling problems inherent in prior through-the-lens implementations. We describe extensions for 6 DOF input devices that do not supersede the default interaction method. We developed a single-authored virtual world builder as a proof of concept application of our framework. Our evaluations found alternate perspectives useful but our implementation of viewing windows proved fatiguing to some users.";0;0;0;0;0;0;0
